{"episode_reward_max": -4.0, "episode_reward_min": -33.0, "episode_reward_mean": -27.82675438596491, "episode_len_mean": 10.986842105263158, "episodes_this_iter": 912, "num_faulty_episodes": 0, "num_healthy_workers": 8, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 630000, "num_agent_steps_trained": 0, "num_env_steps_sampled": 210000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 10000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 721.3556196228698, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 210000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 630000, "episodes_total": 19138, "training_iteration": 21, "timestamp": 1696678262, "time_this_iter_s": 13.88446044921875, "time_total_s": 289.84884881973267, "time_since_restore": 289.84884881973267, "iterations_since_restore": 21, "info/num_env_steps_sampled": 210000, "info/num_env_steps_trained": 0, "info/num_agent_steps_sampled": 630000, "info/num_agent_steps_trained": 0, "sampler_results/episode_reward_max": -4.0, "sampler_results/episode_reward_min": -33.0, "sampler_results/episode_reward_mean": -27.82675438596491, "sampler_results/episode_len_mean": 10.986842105263158, "sampler_results/episodes_this_iter": 912, "sampler_results/num_faulty_episodes": 0, "policy_reward_min/agent_0": -11.0, "policy_reward_min/agent_1": -11.0, "policy_reward_min/agent_2": -11.0, "policy_reward_max/agent_0": 1.0, "policy_reward_max/agent_1": 1.0, "policy_reward_max/agent_2": 1.0, "policy_reward_mean/agent_0": -9.432017543859649, "policy_reward_mean/agent_1": -9.176535087719298, "policy_reward_mean/agent_2": -9.218201754385966, "sampler_perf/mean_raw_obs_processing_ms": 1.6464875966086892, "sampler_perf/mean_inference_ms": 4.271628318712703, "sampler_perf/mean_action_processing_ms": 0.28802991025405733, "sampler_perf/mean_env_wait_ms": 0.1427605369898181, "sampler_perf/mean_env_render_ms": 0.0, "connector_metrics/ObsPreprocessorConnector_ms": 0.0056540844036124605, "connector_metrics/StateBufferConnector_ms": 0.0035169093232405814, "connector_metrics/ViewRequirementAgentConnector_ms": 0.22822443330497072, "timers/training_iteration_time_ms": 12917.784, "timers/sample_time_ms": 8411.978, "timers/synch_weights_time_ms": 11.699, "counters/num_env_steps_sampled": 210000, "counters/num_env_steps_trained": 0, "counters/num_agent_steps_sampled": 630000, "counters/num_agent_steps_trained": 0, "perf/cpu_util_percent": 24.263157894736842, "perf/ram_util_percent": 59.478947368421046, "perf/gpu_util_percent0": 0.06105263157894738, "perf/vram_util_percent0": 0.058341043037280695, "sampler_results/policy_reward_min/agent_0": -11.0, "sampler_results/policy_reward_min/agent_1": -11.0, "sampler_results/policy_reward_min/agent_2": -11.0, "sampler_results/policy_reward_max/agent_0": 1.0, "sampler_results/policy_reward_max/agent_1": 1.0, "sampler_results/policy_reward_max/agent_2": 1.0, "sampler_results/policy_reward_mean/agent_0": -9.432017543859649, "sampler_results/policy_reward_mean/agent_1": -9.176535087719298, "sampler_results/policy_reward_mean/agent_2": -9.218201754385966, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.6464875966086892, "sampler_results/sampler_perf/mean_inference_ms": 4.271628318712703, "sampler_results/sampler_perf/mean_action_processing_ms": 0.28802991025405733, "sampler_results/sampler_perf/mean_env_wait_ms": 0.1427605369898181, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.0056540844036124605, "sampler_results/connector_metrics/StateBufferConnector_ms": 0.0035169093232405814, "sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.22822443330497072, "info/learner/__all__/num_agent_steps_trained": 6144.0, "info/learner/__all__/num_env_steps_trained": 10000.0, "info/learner/__all__/total_loss": 3.419735746383667, "info/learner/agent_0/total_loss": 3.419735746383667, "info/learner/agent_0/policy_loss": -0.021238123739603907, "info/learner/agent_0/vf_loss": 4.763004856109619, "info/learner/agent_0/vf_loss_unclipped": 8.546160907745362, "info/learner/agent_0/vf_explained_var": -0.10087845563888549, "info/learner/agent_0/entropy": 1.489140543937683, "info/learner/agent_0/mean_kl_loss": 0.015377333238720894, "info/learner/agent_0/default_optimizer_lr": 0.0005, "info/learner/agent_0/curr_lr": 0.0005, "info/learner/agent_0/curr_entropy_coeff": 0.01, "info/learner/agent_0/curr_kl_coeff": 0.0, "info/learner/agent_1/total_loss": 1.1296629953384398, "info/learner/agent_1/policy_loss": -0.022447399441152812, "info/learner/agent_1/vf_loss": 4.668616638183594, "info/learner/agent_1/vf_loss_unclipped": 8.544969329833984, "info/learner/agent_1/vf_explained_var": -0.051377408504486084, "info/learner/agent_1/entropy": 1.5043790435791016, "info/learner/agent_1/mean_kl_loss": 0.015721997059881688, "info/learner/agent_1/default_optimizer_lr": 0.0005, "info/learner/agent_1/curr_lr": 0.0005, "info/learner/agent_1/curr_entropy_coeff": 0.01, "info/learner/agent_1/curr_kl_coeff": 0.0, "info/learner/agent_2/total_loss": 1.1354510354995728, "info/learner/agent_2/policy_loss": -0.01950676891952753, "info/learner/agent_2/vf_loss": 4.6790214538574215, "info/learner/agent_2/vf_loss_unclipped": 8.724370632171631, "info/learner/agent_2/vf_explained_var": -0.03544497966766357, "info/learner/agent_2/entropy": 1.479755301475525, "info/learner/agent_2/mean_kl_loss": 0.0168255066126585, "info/learner/agent_2/default_optimizer_lr": 0.0005, "info/learner/agent_2/curr_lr": 0.0005, "info/learner/agent_2/curr_entropy_coeff": 0.01, "info/learner/agent_2/curr_kl_coeff": 0.0, "_timestamp": 1696678262.5299604, "_runtime": 294.78635334968567, "_step": 20, "evaluation/episode_reward_max": -9.0, "evaluation/episode_reward_min": -33.0, "evaluation/episode_reward_mean": -27.67, "evaluation/episode_len_mean": 11.0, "evaluation/episodes_this_iter": 100, "evaluation/num_faulty_episodes": 0, "evaluation/num_agent_steps_sampled_this_iter": 3300, "evaluation/num_env_steps_sampled_this_iter": 1100, "evaluation/timesteps_this_iter": 1100, "evaluation/num_healthy_workers": 0, "evaluation/num_in_flight_async_reqs": 0, "evaluation/num_remote_worker_restarts": 0, "evaluation/sampler_results/episode_reward_max": -9.0, "evaluation/sampler_results/episode_reward_min": -33.0, "evaluation/sampler_results/episode_reward_mean": -27.67, "evaluation/sampler_results/episode_len_mean": 11.0, "evaluation/sampler_results/episodes_this_iter": 100, "evaluation/sampler_results/num_faulty_episodes": 0, "evaluation/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "9ea31dd86ebf5cbb1ba1b2b97c78ecfcf277f7097c2b391e4d43118dc3ce5842", "size": 51500, "path": "media/videos/evaluation/episode_media/env_0_video_19_9ea31dd86ebf5cbb1ba1.mp4"}, {"_type": "video-file", "sha256": "ea6e5e66f58e0bbcb718286c4a637e2b0fb20cd4c7842e65afe92bacb4ca3e90", "size": 54873, "path": "media/videos/evaluation/episode_media/env_0_video_19_ea6e5e66f58e0bbcb718.mp4"}, {"_type": "video-file", "sha256": "8482454c124baa84d34f9edc6e570081ea863642c129476e7de005d4ad9377ec", "size": 51194, "path": "media/videos/evaluation/episode_media/env_0_video_19_8482454c124baa84d34f.mp4"}, {"_type": "video-file", "sha256": "757883d0d078bac5d8c6f83faa6c2d3830a4794a7d183dc77715ab9016e08bea", "size": 54430, "path": "media/videos/evaluation/episode_media/env_0_video_19_757883d0d078bac5d8c6.mp4"}, {"_type": "video-file", "sha256": "386fbf8276e0bac84940ec4372652e0e2e3d34b83bcb36fff37c3f4e4ac5223f", "size": 55228, "path": "media/videos/evaluation/episode_media/env_0_video_19_386fbf8276e0bac84940.mp4"}, {"_type": "video-file", "sha256": "e36d6b14d87394a3e00d5266765614a99d1f307934edb811677de5ba3f858fed", "size": 53764, "path": "media/videos/evaluation/episode_media/env_0_video_19_e36d6b14d87394a3e00d.mp4"}], "captions": false}, "evaluation/policy_reward_min/agent_0": -11.0, "evaluation/policy_reward_min/agent_1": -11.0, "evaluation/policy_reward_min/agent_2": -11.0, "evaluation/policy_reward_max/agent_0": 1.0, "evaluation/policy_reward_max/agent_1": 1.0, "evaluation/policy_reward_max/agent_2": 1.0, "evaluation/policy_reward_mean/agent_0": -8.96, "evaluation/policy_reward_mean/agent_1": -9.55, "evaluation/policy_reward_mean/agent_2": -9.16, "evaluation/sampler_perf/mean_raw_obs_processing_ms": 2.1832949028725737, "evaluation/sampler_perf/mean_inference_ms": 3.691144771653919, "evaluation/sampler_perf/mean_action_processing_ms": 0.2270372062312207, "evaluation/sampler_perf/mean_env_wait_ms": 0.10723918202463899, "evaluation/sampler_perf/mean_env_render_ms": 0.0, "evaluation/connector_metrics/ObsPreprocessorConnector_ms": 0.0032509167989095054, "evaluation/connector_metrics/StateBufferConnector_ms": 0.0024126370747884116, "evaluation/connector_metrics/ViewRequirementAgentConnector_ms": 0.16144736607869467, "evaluation/sampler_results/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "9ea31dd86ebf5cbb1ba1b2b97c78ecfcf277f7097c2b391e4d43118dc3ce5842", "size": 51500, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_19_9ea31dd86ebf5cbb1ba1.mp4"}, {"_type": "video-file", "sha256": "ea6e5e66f58e0bbcb718286c4a637e2b0fb20cd4c7842e65afe92bacb4ca3e90", "size": 54873, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_19_ea6e5e66f58e0bbcb718.mp4"}, {"_type": "video-file", "sha256": "8482454c124baa84d34f9edc6e570081ea863642c129476e7de005d4ad9377ec", "size": 51194, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_19_8482454c124baa84d34f.mp4"}, {"_type": "video-file", "sha256": "757883d0d078bac5d8c6f83faa6c2d3830a4794a7d183dc77715ab9016e08bea", "size": 54430, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_19_757883d0d078bac5d8c6.mp4"}, {"_type": "video-file", "sha256": "386fbf8276e0bac84940ec4372652e0e2e3d34b83bcb36fff37c3f4e4ac5223f", "size": 55228, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_19_386fbf8276e0bac84940.mp4"}, {"_type": "video-file", "sha256": "e36d6b14d87394a3e00d5266765614a99d1f307934edb811677de5ba3f858fed", "size": 53764, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_19_e36d6b14d87394a3e00d.mp4"}], "captions": false}, "evaluation/sampler_results/policy_reward_min/agent_0": -11.0, "evaluation/sampler_results/policy_reward_min/agent_1": -11.0, "evaluation/sampler_results/policy_reward_min/agent_2": -11.0, "evaluation/sampler_results/policy_reward_max/agent_0": 1.0, "evaluation/sampler_results/policy_reward_max/agent_1": 1.0, "evaluation/sampler_results/policy_reward_max/agent_2": 1.0, "evaluation/sampler_results/policy_reward_mean/agent_0": -8.96, "evaluation/sampler_results/policy_reward_mean/agent_1": -9.55, "evaluation/sampler_results/policy_reward_mean/agent_2": -9.16, "evaluation/sampler_results/sampler_perf/mean_raw_obs_processing_ms": 2.1832949028725737, "evaluation/sampler_results/sampler_perf/mean_inference_ms": 3.691144771653919, "evaluation/sampler_results/sampler_perf/mean_action_processing_ms": 0.2270372062312207, "evaluation/sampler_results/sampler_perf/mean_env_wait_ms": 0.10723918202463899, "evaluation/sampler_results/sampler_perf/mean_env_render_ms": 0.0, "evaluation/sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.0032509167989095054, "evaluation/sampler_results/connector_metrics/StateBufferConnector_ms": 0.0024126370747884116, "evaluation/sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.16144736607869467}
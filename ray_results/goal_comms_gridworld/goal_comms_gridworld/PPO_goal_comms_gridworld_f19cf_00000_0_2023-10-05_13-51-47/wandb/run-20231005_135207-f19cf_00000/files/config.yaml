wandb_version: 1

extra_python_environs_for_driver:
  desc: null
  value: {}
extra_python_environs_for_worker:
  desc: null
  value: {}
num_gpus:
  desc: null
  value: 1
num_cpus_per_worker:
  desc: null
  value: 1
num_gpus_per_worker:
  desc: null
  value: 0
_fake_gpus:
  desc: null
  value: false
num_learner_workers:
  desc: null
  value: 0
num_gpus_per_learner_worker:
  desc: null
  value: 0
num_cpus_per_learner_worker:
  desc: null
  value: 1
local_gpu_idx:
  desc: null
  value: 0
custom_resources_per_worker:
  desc: null
  value: {}
placement_strategy:
  desc: null
  value: PACK
eager_tracing:
  desc: null
  value: true
eager_max_retraces:
  desc: null
  value: 20
tf_session_args:
  desc: null
  value:
    intra_op_parallelism_threads: 2
    inter_op_parallelism_threads: 2
    gpu_options:
      allow_growth: true
    log_device_placement: false
    device_count:
      CPU: 1
    allow_soft_placement: true
local_tf_session_args:
  desc: null
  value:
    intra_op_parallelism_threads: 8
    inter_op_parallelism_threads: 8
torch_compile_learner:
  desc: null
  value: false
torch_compile_learner_what_to_compile:
  desc: null
  value: TorchCompileWhatToCompile.FORWARD_TRAIN
torch_compile_learner_dynamo_backend:
  desc: null
  value: inductor
torch_compile_learner_dynamo_mode:
  desc: null
  value: null
torch_compile_worker:
  desc: null
  value: false
torch_compile_worker_dynamo_backend:
  desc: null
  value: onnxrt
torch_compile_worker_dynamo_mode:
  desc: null
  value: null
env:
  desc: null
  value: goal_comms_gridworld
env_config:
  desc: null
  value:
    render_mode: rgb_array
    world_shape:
    - 5
    - 5
    num_agents: 1
    max_episode_len: 10
    goal_shift: 0
    scalar_obs: false
observation_space:
  desc: null
  value: null
action_space:
  desc: null
  value: null
env_task_fn:
  desc: null
  value: null
render_env:
  desc: null
  value: false
clip_rewards:
  desc: null
  value: null
normalize_actions:
  desc: null
  value: true
clip_actions:
  desc: null
  value: true
disable_env_checking:
  desc: null
  value: false
auto_wrap_old_gym_envs:
  desc: null
  value: true
action_mask_key:
  desc: null
  value: action_mask
_is_atari:
  desc: null
  value: null
env_runner_cls:
  desc: null
  value: null
num_envs_per_worker:
  desc: null
  value: 1
sample_collector:
  desc: null
  value: ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector
sample_async:
  desc: null
  value: false
enable_connectors:
  desc: null
  value: true
update_worker_filter_stats:
  desc: null
  value: true
use_worker_filter_stats:
  desc: null
  value: true
rollout_fragment_length:
  desc: null
  value: auto
batch_mode:
  desc: null
  value: truncate_episodes
remote_worker_envs:
  desc: null
  value: false
remote_env_batch_wait_ms:
  desc: null
  value: 0
validate_workers_after_construction:
  desc: null
  value: true
preprocessor_pref:
  desc: null
  value: deepmind
observation_filter:
  desc: null
  value: NoFilter
compress_observations:
  desc: null
  value: false
enable_tf1_exec_eagerly:
  desc: null
  value: false
sampler_perf_stats_ema_coef:
  desc: null
  value: null
gamma:
  desc: null
  value: 0.99
lr:
  desc: null
  value: 0.0005
grad_clip:
  desc: null
  value: null
grad_clip_by:
  desc: null
  value: global_norm
train_batch_size:
  desc: null
  value: 10000
model:
  desc: null
  value:
    _disable_preprocessor_api: false
    _disable_action_flattening: false
    fcnet_hiddens:
    - 256
    - 256
    fcnet_activation: tanh
    conv_filters: null
    conv_activation: relu
    post_fcnet_hiddens: []
    post_fcnet_activation: relu
    free_log_std: false
    no_final_linear: false
    vf_share_layers: false
    use_lstm: false
    max_seq_len: 20
    lstm_cell_size: 256
    lstm_use_prev_action: false
    lstm_use_prev_reward: false
    _time_major: false
    use_attention: false
    attention_num_transformer_units: 1
    attention_dim: 64
    attention_num_heads: 1
    attention_head_dim: 32
    attention_memory_inference: 50
    attention_memory_training: 50
    attention_position_wise_mlp_dim: 32
    attention_init_gru_gate_bias: 2.0
    attention_use_n_prev_actions: 0
    attention_use_n_prev_rewards: 0
    framestack: true
    dim: 84
    grayscale: false
    zero_mean: true
    custom_model: null
    custom_model_config: {}
    custom_action_dist: null
    custom_preprocessor: null
    encoder_latent_dim: null
    always_check_shapes: false
    lstm_use_prev_action_reward: -1
    _use_default_native_models: -1
optimizer:
  desc: null
  value: {}
max_requests_in_flight_per_sampler_worker:
  desc: null
  value: 2
_learner_class:
  desc: null
  value: null
_enable_learner_api:
  desc: null
  value: true
explore:
  desc: null
  value: true
exploration_config:
  desc: null
  value: {}
algorithm_config_overrides_per_module:
  desc: null
  value: {}
policy_map_capacity:
  desc: null
  value: 100
policy_mapping_fn:
  desc: null
  value: <function get_ppo_config.<locals>.policy_mapping_fn at 0x7f6e69776ef0>
policies_to_train:
  desc: null
  value: null
policy_states_are_swappable:
  desc: null
  value: false
observation_fn:
  desc: null
  value: null
count_steps_by:
  desc: null
  value: env_steps
input_config:
  desc: null
  value: {}
actions_in_input_normalized:
  desc: null
  value: false
postprocess_inputs:
  desc: null
  value: false
shuffle_buffer_size:
  desc: null
  value: 0
output:
  desc: null
  value: null
output_config:
  desc: null
  value: {}
output_compress_columns:
  desc: null
  value:
  - obs
  - new_obs
output_max_file_size:
  desc: null
  value: 67108864
offline_sampling:
  desc: null
  value: false
evaluation_interval:
  desc: null
  value: 10
evaluation_duration:
  desc: null
  value: 100
evaluation_duration_unit:
  desc: null
  value: episodes
evaluation_sample_timeout_s:
  desc: null
  value: 180.0
evaluation_parallel_to_training:
  desc: null
  value: false
evaluation_config:
  desc: null
  value: null
off_policy_estimation_methods:
  desc: null
  value: {}
ope_split_batch_by_episode:
  desc: null
  value: true
evaluation_num_workers:
  desc: null
  value: 0
always_attach_evaluation_results:
  desc: null
  value: false
enable_async_evaluation:
  desc: null
  value: false
in_evaluation:
  desc: null
  value: false
sync_filters_on_rollout_workers_timeout_s:
  desc: null
  value: 60.0
keep_per_episode_custom_metrics:
  desc: null
  value: false
metrics_episode_collection_timeout_s:
  desc: null
  value: 60.0
metrics_num_episodes_for_smoothing:
  desc: null
  value: 100
min_time_s_per_iteration:
  desc: null
  value: null
min_train_timesteps_per_iteration:
  desc: null
  value: 0
min_sample_timesteps_per_iteration:
  desc: null
  value: 0
export_native_model_files:
  desc: null
  value: false
checkpoint_trainable_policies_only:
  desc: null
  value: false
logger_creator:
  desc: null
  value: null
logger_config:
  desc: null
  value: null
log_level:
  desc: null
  value: WARN
log_sys_usage:
  desc: null
  value: true
fake_sampler:
  desc: null
  value: false
seed:
  desc: null
  value: null
ignore_worker_failures:
  desc: null
  value: false
recreate_failed_workers:
  desc: null
  value: false
max_num_worker_restarts:
  desc: null
  value: 1000
delay_between_worker_restarts_s:
  desc: null
  value: 60.0
restart_failed_sub_environments:
  desc: null
  value: false
num_consecutive_worker_failures_tolerance:
  desc: null
  value: 100
worker_health_probe_timeout_s:
  desc: null
  value: 60
worker_restore_timeout_s:
  desc: null
  value: 1800
rl_module_spec:
  desc: null
  value: 'MultiAgentRLModuleSpec(marl_module_class=<class ''ray.rllib.core.rl_module.marl_module.MultiAgentRLModule''>,
    module_specs={''agent_0'': SingleAgentRLModuleSpec(module_class=<class ''ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule''>,
    observation_space=None, action_space=None, model_config_dict={''fcnet_hiddens'':
    [256, 256]}, catalog_class=<class ''ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog''>,
    load_state_path=None)}, load_state_path=None, modules_to_load=None)'
_enable_rl_module_api:
  desc: null
  value: true
_AlgorithmConfig__prior_exploration_config:
  desc: null
  value:
    type: StochasticSampling
_tf_policy_handles_more_than_one_loss:
  desc: null
  value: false
_disable_preprocessor_api:
  desc: null
  value: false
_disable_action_flattening:
  desc: null
  value: false
_disable_execution_plan_api:
  desc: null
  value: true
_disable_initialize_loss_from_dummy_batch:
  desc: null
  value: false
simple_optimizer:
  desc: null
  value: true
policy_map_cache:
  desc: null
  value: -1
worker_cls:
  desc: null
  value: -1
synchronize_filters:
  desc: null
  value: -1
replay_sequence_length:
  desc: null
  value: null
lr_schedule:
  desc: null
  value: null
use_critic:
  desc: null
  value: true
use_gae:
  desc: null
  value: true
use_kl_loss:
  desc: null
  value: true
kl_coeff:
  desc: null
  value: 0.0
kl_target:
  desc: null
  value: 0.01
sgd_minibatch_size:
  desc: null
  value: 2048
num_sgd_iter:
  desc: null
  value: 5
shuffle_sequences:
  desc: null
  value: true
vf_loss_coeff:
  desc: null
  value: 0.25
entropy_coeff:
  desc: null
  value: 0.01
entropy_coeff_schedule:
  desc: null
  value: null
clip_param:
  desc: null
  value: 0.2
vf_clip_param:
  desc: null
  value: 10.0
vf_share_layers:
  desc: null
  value: -1
lambda:
  desc: null
  value: 0.95
input:
  desc: null
  value: sampler
policies:
  desc: null
  value:
    agent_0:
    - null
    - null
    - null
    - null
create_env_on_driver:
  desc: null
  value: false
custom_eval_function:
  desc: null
  value: null
framework:
  desc: null
  value: torch
num_cpus_for_driver:
  desc: null
  value: 1
num_workers:
  desc: null
  value: 8
_wandb:
  desc: null
  value:
    python_version: 3.10.6
    cli_version: 0.15.10
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1696510327.207574
    t:
      1:
      - 1
      - 2
      - 3
      - 12
      - 30
      - 55
      2:
      - 1
      - 2
      - 3
      - 12
      - 30
      - 55
      3:
      - 13
      - 14
      - 16
      - 19
      - 23
      4: 3.10.6
      5: 0.15.10
      8:
      - 8
trial_log_path:
  desc: null
  value: /root/ray_results/goal_comms_gridworld/PPO_goal_comms_gridworld_f19cf_00000_0_2023-10-05_13-51-47
__stdout_file__:
  desc: null
  value: null
__stderr_file__:
  desc: null
  value: null
trial_id:
  desc: null
  value: f19cf_00000
date:
  desc: null
  value: 2023-10-05_13-58-54
pid:
  desc: null
  value: 26439
hostname:
  desc: null
  value: DYLAN-PC
node_ip:
  desc: null
  value: 172.30.135.148

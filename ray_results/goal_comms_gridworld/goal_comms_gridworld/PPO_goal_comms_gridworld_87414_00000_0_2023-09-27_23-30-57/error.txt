Failure # 1 (occurred at 2023-09-27_23-31-20)
The actor died because of an error raised in its creation task, [36mray::PPO.__init__()[39m (pid=15289, ip=172.17.137.197, actor_id=f05448365bcc0dc984d483f301000000, repr=PPO)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/worker_set.py", line 227, in _setup
    self.add_workers(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/worker_set.py", line 593, in add_workers
    raise result.get()
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/utils/actor_manager.py", line 481, in __fetch_result
    result = ray.get(r)
ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, [36mray::RolloutWorker.__init__()[39m (pid=15439, ip=172.17.137.197, actor_id=819fc432e375212bb1c33a4801000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fab5977c760>)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 525, in __init__
    self._update_policy_map(policy_dict=self.policy_dict)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 1727, in _update_policy_map
    self._build_policy_map(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 1838, in _build_policy_map
    new_policy = create_policy_for_framework(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/utils/policy.py", line 142, in create_policy_for_framework
    return policy_class(observation_space, action_space, merged_config)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/ppo/ppo_torch_policy.py", line 49, in __init__
    TorchPolicyV2.__init__(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/policy/torch_policy_v2.py", line 180, in __init__
    self.view_requirements = self.model.update_default_view_requirements(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/core/rl_module/rl_module.py", line 513, in update_default_view_requirements
    max_seq_len = self.config.model_config_dict["max_seq_len"]
KeyError: 'max_seq_len'

During handling of the above exception, another exception occurred:

[36mray::PPO.__init__()[39m (pid=15289, ip=172.17.137.197, actor_id=f05448365bcc0dc984d483f301000000, repr=PPO)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/algorithm.py", line 517, in __init__
    super().__init__(
  File "/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py", line 185, in __init__
    self.setup(copy.deepcopy(self.config))
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/algorithm.py", line 639, in setup
    self.workers = WorkerSet(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/worker_set.py", line 179, in __init__
    raise e.args[0].args[2]
KeyError: 'max_seq_len'

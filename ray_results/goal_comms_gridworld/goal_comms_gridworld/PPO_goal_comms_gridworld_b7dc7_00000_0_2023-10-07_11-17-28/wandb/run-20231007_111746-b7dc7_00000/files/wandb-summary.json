{"episode_reward_max": 1.0, "episode_reward_min": -33.0, "episode_reward_mean": -27.801969365426697, "episode_len_mean": 10.956236323851204, "episodes_this_iter": 914, "num_faulty_episodes": 0, "num_healthy_workers": 8, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 0, "num_env_steps_sampled": 240000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 10000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 879.4261424377968, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 240000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 720000, "episodes_total": 21897, "training_iteration": 24, "timestamp": 1696674164, "time_this_iter_s": 11.390580177307129, "time_total_s": 278.71160316467285, "time_since_restore": 278.71160316467285, "iterations_since_restore": 24, "info/num_env_steps_sampled": 240000, "info/num_env_steps_trained": 0, "info/num_agent_steps_sampled": 720000, "info/num_agent_steps_trained": 0, "sampler_results/episode_reward_max": 1.0, "sampler_results/episode_reward_min": -33.0, "sampler_results/episode_reward_mean": -27.801969365426697, "sampler_results/episode_len_mean": 10.956236323851204, "sampler_results/episodes_this_iter": 914, "sampler_results/num_faulty_episodes": 0, "policy_reward_min/agent_0": -11.0, "policy_reward_min/agent_1": -11.0, "policy_reward_min/agent_2": -11.0, "policy_reward_max/agent_0": 1.0, "policy_reward_max/agent_1": 1.0, "policy_reward_max/agent_2": 1.0, "policy_reward_mean/agent_0": -9.342450765864333, "policy_reward_mean/agent_1": -9.314004376367615, "policy_reward_mean/agent_2": -9.145514223194748, "sampler_perf/mean_raw_obs_processing_ms": 1.6554360780502233, "sampler_perf/mean_inference_ms": 4.3604767912323155, "sampler_perf/mean_action_processing_ms": 0.29312585306663785, "sampler_perf/mean_env_wait_ms": 0.14539240335718875, "sampler_perf/mean_env_render_ms": 0.0, "connector_metrics/ObsPreprocessorConnector_ms": 0.0057473572216966045, "connector_metrics/StateBufferConnector_ms": 0.0034918670320406523, "connector_metrics/ViewRequirementAgentConnector_ms": 0.22816401515713058, "timers/training_iteration_time_ms": 11185.509, "timers/sample_time_ms": 8687.688, "timers/synch_weights_time_ms": 11.514, "counters/num_env_steps_sampled": 240000, "counters/num_env_steps_trained": 0, "counters/num_agent_steps_sampled": 720000, "counters/num_agent_steps_trained": 0, "perf/cpu_util_percent": 29.24375, "perf/ram_util_percent": 58.2, "perf/gpu_util_percent0": 0.01625, "perf/vram_util_percent0": 0.05389404296875, "sampler_results/policy_reward_min/agent_0": -11.0, "sampler_results/policy_reward_min/agent_1": -11.0, "sampler_results/policy_reward_min/agent_2": -11.0, "sampler_results/policy_reward_max/agent_0": 1.0, "sampler_results/policy_reward_max/agent_1": 1.0, "sampler_results/policy_reward_max/agent_2": 1.0, "sampler_results/policy_reward_mean/agent_0": -9.342450765864333, "sampler_results/policy_reward_mean/agent_1": -9.314004376367615, "sampler_results/policy_reward_mean/agent_2": -9.145514223194748, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.6554360780502233, "sampler_results/sampler_perf/mean_inference_ms": 4.3604767912323155, "sampler_results/sampler_perf/mean_action_processing_ms": 0.29312585306663785, "sampler_results/sampler_perf/mean_env_wait_ms": 0.14539240335718875, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.0057473572216966045, "sampler_results/connector_metrics/StateBufferConnector_ms": 0.0034918670320406523, "sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.22816401515713058, "info/learner/__all__/num_agent_steps_trained": 6144.0, "info/learner/__all__/num_env_steps_trained": 10000.0, "info/learner/__all__/total_loss": 2.576671533584595, "info/learner/agent_0/total_loss": 2.576671533584595, "info/learner/agent_0/policy_loss": -0.007526488555595279, "info/learner/agent_0/vf_loss": 3.567763910293579, "info/learner/agent_0/vf_loss_unclipped": 5.643357582092285, "info/learner/agent_0/vf_explained_var": 0.32322786569595335, "info/learner/agent_0/entropy": 1.180238552093506, "info/learner/agent_0/mean_kl_loss": 0.0065588809456676245, "info/learner/agent_0/default_optimizer_lr": 0.0005, "info/learner/agent_0/curr_lr": 0.0005, "info/learner/agent_0/curr_entropy_coeff": 0.01, "info/learner/agent_0/curr_kl_coeff": 0.0, "info/learner/agent_1/total_loss": 0.8334911870956421, "info/learner/agent_1/policy_loss": -0.007406069962307811, "info/learner/agent_1/vf_loss": 3.409505634307861, "info/learner/agent_1/vf_loss_unclipped": 5.527542724609375, "info/learner/agent_1/vf_explained_var": 0.34382158517837524, "info/learner/agent_1/entropy": 1.147915186882019, "info/learner/agent_1/mean_kl_loss": 0.0070664203073829415, "info/learner/agent_1/default_optimizer_lr": 0.0005, "info/learner/agent_1/curr_lr": 0.0005, "info/learner/agent_1/curr_entropy_coeff": 0.01, "info/learner/agent_1/curr_kl_coeff": 0.0, "info/learner/agent_2/total_loss": 0.8705682516098022, "info/learner/agent_2/policy_loss": -0.00717772537842393, "info/learner/agent_2/vf_loss": 3.558807821273804, "info/learner/agent_2/vf_loss_unclipped": 5.69503116607666, "info/learner/agent_2/vf_explained_var": 0.3533333873748779, "info/learner/agent_2/entropy": 1.1955972957611083, "info/learner/agent_2/mean_kl_loss": 0.008738772720098495, "info/learner/agent_2/default_optimizer_lr": 0.0005, "info/learner/agent_2/curr_lr": 0.0005, "info/learner/agent_2/curr_entropy_coeff": 0.01, "info/learner/agent_2/curr_kl_coeff": 0.0, "_timestamp": 1696674164.2667418, "_runtime": 297.41365480422974, "_step": 23, "evaluation/episode_reward_max": -9.0, "evaluation/episode_reward_min": -33.0, "evaluation/episode_reward_mean": -26.78, "evaluation/episode_len_mean": 11.0, "evaluation/episodes_this_iter": 100, "evaluation/num_faulty_episodes": 0, "evaluation/num_agent_steps_sampled_this_iter": 3300, "evaluation/num_env_steps_sampled_this_iter": 1100, "evaluation/timesteps_this_iter": 1100, "evaluation/num_healthy_workers": 0, "evaluation/num_in_flight_async_reqs": 0, "evaluation/num_remote_worker_restarts": 0, "evaluation/sampler_results/episode_reward_max": -9.0, "evaluation/sampler_results/episode_reward_min": -33.0, "evaluation/sampler_results/episode_reward_mean": -26.78, "evaluation/sampler_results/episode_len_mean": 11.0, "evaluation/sampler_results/episodes_this_iter": 100, "evaluation/sampler_results/num_faulty_episodes": 0, "evaluation/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "47c67ad09a1c9e9e20d2a44cbd51490d2f96a81b2b4406e644188fa1e6edac14", "size": 57845, "path": "media/videos/evaluation/episode_media/env_0_video_19_47c67ad09a1c9e9e20d2.mp4"}, {"_type": "video-file", "sha256": "a724a8bd93d2af59f0653ab41f178e666f44b3e94df2664e04d25614a58a2832", "size": 60120, "path": "media/videos/evaluation/episode_media/env_0_video_19_a724a8bd93d2af59f065.mp4"}, {"_type": "video-file", "sha256": "5f29c1c49a7dcd516d0b5bae288d72e85121bad4917d690bf10988eaff76f2ee", "size": 51820, "path": "media/videos/evaluation/episode_media/env_0_video_19_5f29c1c49a7dcd516d0b.mp4"}, {"_type": "video-file", "sha256": "bbd0f46ed5780c49ec84be3f983adc27e2c3a64c2106b17ae988bcca1584fdd7", "size": 55637, "path": "media/videos/evaluation/episode_media/env_0_video_19_bbd0f46ed5780c49ec84.mp4"}, {"_type": "video-file", "sha256": "390e4d1dca4dcc221fcf9165f9093a0150b05d3c32e808d0974111fb1da6d4e7", "size": 56594, "path": "media/videos/evaluation/episode_media/env_0_video_19_390e4d1dca4dcc221fcf.mp4"}, {"_type": "video-file", "sha256": "5365ffb29e7eea659c20bbe21eeeb1dd84977c007e6c6d66b4a8007ec714a0b5", "size": 53624, "path": "media/videos/evaluation/episode_media/env_0_video_19_5365ffb29e7eea659c20.mp4"}], "captions": false}, "evaluation/policy_reward_min/agent_0": -11.0, "evaluation/policy_reward_min/agent_1": -11.0, "evaluation/policy_reward_min/agent_2": -11.0, "evaluation/policy_reward_max/agent_0": 1.0, "evaluation/policy_reward_max/agent_1": 1.0, "evaluation/policy_reward_max/agent_2": 1.0, "evaluation/policy_reward_mean/agent_0": -9.27, "evaluation/policy_reward_mean/agent_1": -8.54, "evaluation/policy_reward_mean/agent_2": -8.97, "evaluation/sampler_perf/mean_raw_obs_processing_ms": 2.302451330875603, "evaluation/sampler_perf/mean_inference_ms": 3.7455189395958275, "evaluation/sampler_perf/mean_action_processing_ms": 0.23759142586666035, "evaluation/sampler_perf/mean_env_wait_ms": 0.11729024205084336, "evaluation/sampler_perf/mean_env_render_ms": 0.0, "evaluation/connector_metrics/ObsPreprocessorConnector_ms": 0.003686189651489258, "evaluation/connector_metrics/StateBufferConnector_ms": 0.0024216175079345703, "evaluation/connector_metrics/ViewRequirementAgentConnector_ms": 0.16424965858459473, "evaluation/sampler_results/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "47c67ad09a1c9e9e20d2a44cbd51490d2f96a81b2b4406e644188fa1e6edac14", "size": 57845, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_19_47c67ad09a1c9e9e20d2.mp4"}, {"_type": "video-file", "sha256": "a724a8bd93d2af59f0653ab41f178e666f44b3e94df2664e04d25614a58a2832", "size": 60120, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_19_a724a8bd93d2af59f065.mp4"}, {"_type": "video-file", "sha256": "5f29c1c49a7dcd516d0b5bae288d72e85121bad4917d690bf10988eaff76f2ee", "size": 51820, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_19_5f29c1c49a7dcd516d0b.mp4"}, {"_type": "video-file", "sha256": "bbd0f46ed5780c49ec84be3f983adc27e2c3a64c2106b17ae988bcca1584fdd7", "size": 55637, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_19_bbd0f46ed5780c49ec84.mp4"}, {"_type": "video-file", "sha256": "390e4d1dca4dcc221fcf9165f9093a0150b05d3c32e808d0974111fb1da6d4e7", "size": 56594, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_19_390e4d1dca4dcc221fcf.mp4"}, {"_type": "video-file", "sha256": "5365ffb29e7eea659c20bbe21eeeb1dd84977c007e6c6d66b4a8007ec714a0b5", "size": 53624, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_19_5365ffb29e7eea659c20.mp4"}], "captions": false}, "evaluation/sampler_results/policy_reward_min/agent_0": -11.0, "evaluation/sampler_results/policy_reward_min/agent_1": -11.0, "evaluation/sampler_results/policy_reward_min/agent_2": -11.0, "evaluation/sampler_results/policy_reward_max/agent_0": 1.0, "evaluation/sampler_results/policy_reward_max/agent_1": 1.0, "evaluation/sampler_results/policy_reward_max/agent_2": 1.0, "evaluation/sampler_results/policy_reward_mean/agent_0": -9.27, "evaluation/sampler_results/policy_reward_mean/agent_1": -8.54, "evaluation/sampler_results/policy_reward_mean/agent_2": -8.97, "evaluation/sampler_results/sampler_perf/mean_raw_obs_processing_ms": 2.302451330875603, "evaluation/sampler_results/sampler_perf/mean_inference_ms": 3.7455189395958275, "evaluation/sampler_results/sampler_perf/mean_action_processing_ms": 0.23759142586666035, "evaluation/sampler_results/sampler_perf/mean_env_wait_ms": 0.11729024205084336, "evaluation/sampler_results/sampler_perf/mean_env_render_ms": 0.0, "evaluation/sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.003686189651489258, "evaluation/sampler_results/connector_metrics/StateBufferConnector_ms": 0.0024216175079345703, "evaluation/sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.16424965858459473}
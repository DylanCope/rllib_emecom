{"episode_reward_max": -5.0, "episode_reward_min": -33.0, "episode_reward_mean": -28.11453744493392, "episode_len_mean": 10.98898678414097, "episodes_this_iter": 908, "num_faulty_episodes": 0, "num_healthy_workers": 8, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 300000, "num_agent_steps_trained": 0, "num_env_steps_sampled": 100000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 10000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 929.3374512509872, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 100000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 300000, "episodes_total": 9108, "training_iteration": 10, "timestamp": 1696523453, "time_this_iter_s": 18.17865300178528, "time_total_s": 118.58831405639648, "time_since_restore": 118.58831405639648, "iterations_since_restore": 10, "info/num_env_steps_sampled": 100000, "info/num_env_steps_trained": 0, "info/num_agent_steps_sampled": 300000, "info/num_agent_steps_trained": 0, "sampler_results/episode_reward_max": -5.0, "sampler_results/episode_reward_min": -33.0, "sampler_results/episode_reward_mean": -28.11453744493392, "sampler_results/episode_len_mean": 10.98898678414097, "sampler_results/episodes_this_iter": 908, "sampler_results/num_faulty_episodes": 0, "policy_reward_min/agent_0": -11.0, "policy_reward_min/agent_1": -11.0, "policy_reward_min/agent_2": -11.0, "policy_reward_max/agent_0": 1.0, "policy_reward_max/agent_1": 1.0, "policy_reward_max/agent_2": 1.0, "policy_reward_mean/agent_0": -9.455947136563877, "policy_reward_mean/agent_1": -9.182819383259911, "policy_reward_mean/agent_2": -9.475770925110131, "sampler_perf/mean_raw_obs_processing_ms": 1.6484762002514088, "sampler_perf/mean_inference_ms": 4.454730111239122, "sampler_perf/mean_action_processing_ms": 0.2957991205403982, "sampler_perf/mean_env_wait_ms": 0.14632703755938156, "sampler_perf/mean_env_render_ms": 0.0, "connector_metrics/ObsPreprocessorConnector_ms": 0.005706510179718511, "connector_metrics/StateBufferConnector_ms": 0.003446706416148271, "connector_metrics/ViewRequirementAgentConnector_ms": 0.2253603917736664, "timers/training_iteration_time_ms": 11098.532, "timers/sample_time_ms": 9274.991, "timers/synch_weights_time_ms": 12.028, "counters/num_env_steps_sampled": 100000, "counters/num_env_steps_trained": 0, "counters/num_agent_steps_sampled": 300000, "counters/num_agent_steps_trained": 0, "perf/cpu_util_percent": 24.417391304347827, "perf/ram_util_percent": 63.71739130434783, "perf/gpu_util_percent0": 0.043043478260869565, "perf/vram_util_percent0": 0.07907679461050728, "sampler_results/policy_reward_min/agent_0": -11.0, "sampler_results/policy_reward_min/agent_1": -11.0, "sampler_results/policy_reward_min/agent_2": -11.0, "sampler_results/policy_reward_max/agent_0": 1.0, "sampler_results/policy_reward_max/agent_1": 1.0, "sampler_results/policy_reward_max/agent_2": 1.0, "sampler_results/policy_reward_mean/agent_0": -9.455947136563877, "sampler_results/policy_reward_mean/agent_1": -9.182819383259911, "sampler_results/policy_reward_mean/agent_2": -9.475770925110131, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.6484762002514088, "sampler_results/sampler_perf/mean_inference_ms": 4.454730111239122, "sampler_results/sampler_perf/mean_action_processing_ms": 0.2957991205403982, "sampler_results/sampler_perf/mean_env_wait_ms": 0.14632703755938156, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.005706510179718511, "sampler_results/connector_metrics/StateBufferConnector_ms": 0.003446706416148271, "sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.2253603917736664, "info/learner/__all__/num_agent_steps_trained": 6144.0, "info/learner/__all__/num_env_steps_trained": 10000.0, "info/learner/__all__/total_loss": 3.856006870269775, "info/learner/agent_0/total_loss": 3.856006870269775, "info/learner/agent_0/policy_loss": -0.004605203773826361, "info/learner/agent_0/vf_loss": 5.1770345497131345, "info/learner/agent_0/vf_loss_unclipped": 9.348740882873535, "info/learner/agent_0/vf_explained_var": 0.0179271936416626, "info/learner/agent_0/entropy": 1.5760439395904542, "info/learner/agent_0/mean_kl_loss": 0.007376373335719108, "info/learner/agent_0/default_optimizer_lr": 0.0005, "info/learner/agent_0/curr_lr": 0.0005, "info/learner/agent_0/curr_entropy_coeff": 0.01, "info/learner/agent_0/curr_kl_coeff": 0.0, "info/learner/agent_1/total_loss": 1.3046489429473878, "info/learner/agent_1/policy_loss": -0.009385295808315278, "info/learner/agent_1/vf_loss": 5.318287086486817, "info/learner/agent_1/vf_loss_unclipped": 10.211318969726562, "info/learner/agent_1/vf_explained_var": 0.009027349948883056, "info/learner/agent_1/entropy": 1.5537530946731568, "info/learner/agent_1/mean_kl_loss": 0.010126376412808896, "info/learner/agent_1/default_optimizer_lr": 0.0005, "info/learner/agent_1/curr_lr": 0.0005, "info/learner/agent_1/curr_entropy_coeff": 0.01, "info/learner/agent_1/curr_kl_coeff": 0.0, "info/learner/agent_2/total_loss": 1.277464919090271, "info/learner/agent_2/policy_loss": -0.007338645756244659, "info/learner/agent_2/vf_loss": 5.202899723052979, "info/learner/agent_2/vf_loss_unclipped": 9.670589904785157, "info/learner/agent_2/vf_explained_var": 0.0014530086517333984, "info/learner/agent_2/entropy": 1.592137212753296, "info/learner/agent_2/mean_kl_loss": 0.008828128762543202, "info/learner/agent_2/default_optimizer_lr": 0.0005, "info/learner/agent_2/curr_lr": 0.0005, "info/learner/agent_2/curr_entropy_coeff": 0.01, "info/learner/agent_2/curr_kl_coeff": 0.0, "_timestamp": 1696523454.3894007, "_runtime": 123.19314360618591, "_step": 9, "evaluation/episode_reward_max": -9.0, "evaluation/episode_reward_min": -33.0, "evaluation/episode_reward_mean": -27.83, "evaluation/episode_len_mean": 10.99, "evaluation/episodes_this_iter": 100, "evaluation/num_faulty_episodes": 0, "evaluation/num_agent_steps_sampled_this_iter": 3297, "evaluation/num_env_steps_sampled_this_iter": 1099, "evaluation/timesteps_this_iter": 1099, "evaluation/num_healthy_workers": 0, "evaluation/num_in_flight_async_reqs": 0, "evaluation/num_remote_worker_restarts": 0, "evaluation/sampler_results/episode_reward_max": -9.0, "evaluation/sampler_results/episode_reward_min": -33.0, "evaluation/sampler_results/episode_reward_mean": -27.83, "evaluation/sampler_results/episode_len_mean": 10.99, "evaluation/sampler_results/episodes_this_iter": 100, "evaluation/sampler_results/num_faulty_episodes": 0, "evaluation/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "c0c73dce937f32c9cdce54d57781f3caf5e866ba567cf38b3221542326e6a34a", "size": 50565, "path": "media/videos/evaluation/episode_media/env_0_video_9_c0c73dce937f32c9cdce.mp4"}, {"_type": "video-file", "sha256": "a205ed03a514449944e4a5059b4806e102692e08a6dd84463f44a2738f16ea67", "size": 52982, "path": "media/videos/evaluation/episode_media/env_0_video_9_a205ed03a514449944e4.mp4"}, {"_type": "video-file", "sha256": "9b77e7df20490b9688925812fb8415d0d125f9d22326046fbccd5c5871e66d55", "size": 53302, "path": "media/videos/evaluation/episode_media/env_0_video_9_9b77e7df20490b968892.mp4"}, {"_type": "video-file", "sha256": "789e9e47f2e713299ce2149e1730cd258355a7d4361dc967daceee8cc4d78243", "size": 52185, "path": "media/videos/evaluation/episode_media/env_0_video_9_789e9e47f2e713299ce2.mp4"}, {"_type": "video-file", "sha256": "f6229b35d0d2be30498d86a152023f71dcafc2d2242b995f2353661e3af8ec85", "size": 56656, "path": "media/videos/evaluation/episode_media/env_0_video_9_f6229b35d0d2be30498d.mp4"}, {"_type": "video-file", "sha256": "21c3b18aeb0fc202505f14c166f28e908ba3edcfc700f9ab3c15ef71ed9f67a0", "size": 53048, "path": "media/videos/evaluation/episode_media/env_0_video_9_21c3b18aeb0fc202505f.mp4"}], "captions": false}, "evaluation/policy_reward_min/agent_0": -11.0, "evaluation/policy_reward_min/agent_1": -11.0, "evaluation/policy_reward_min/agent_2": -11.0, "evaluation/policy_reward_max/agent_0": 1.0, "evaluation/policy_reward_max/agent_1": 1.0, "evaluation/policy_reward_max/agent_2": 1.0, "evaluation/policy_reward_mean/agent_0": -8.73, "evaluation/policy_reward_mean/agent_1": -9.92, "evaluation/policy_reward_mean/agent_2": -9.18, "evaluation/sampler_perf/mean_raw_obs_processing_ms": 2.3504840243946417, "evaluation/sampler_perf/mean_inference_ms": 3.8959264755249023, "evaluation/sampler_perf/mean_action_processing_ms": 0.24940924210981893, "evaluation/sampler_perf/mean_env_wait_ms": 0.12068098241632635, "evaluation/sampler_perf/mean_env_render_ms": 0.0, "evaluation/connector_metrics/ObsPreprocessorConnector_ms": 0.00397793451944987, "evaluation/connector_metrics/StateBufferConnector_ms": 0.0025942325592041016, "evaluation/connector_metrics/ViewRequirementAgentConnector_ms": 0.17690141995747885, "evaluation/sampler_results/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "c0c73dce937f32c9cdce54d57781f3caf5e866ba567cf38b3221542326e6a34a", "size": 50565, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_9_c0c73dce937f32c9cdce.mp4"}, {"_type": "video-file", "sha256": "a205ed03a514449944e4a5059b4806e102692e08a6dd84463f44a2738f16ea67", "size": 52982, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_9_a205ed03a514449944e4.mp4"}, {"_type": "video-file", "sha256": "9b77e7df20490b9688925812fb8415d0d125f9d22326046fbccd5c5871e66d55", "size": 53302, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_9_9b77e7df20490b968892.mp4"}, {"_type": "video-file", "sha256": "789e9e47f2e713299ce2149e1730cd258355a7d4361dc967daceee8cc4d78243", "size": 52185, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_9_789e9e47f2e713299ce2.mp4"}, {"_type": "video-file", "sha256": "f6229b35d0d2be30498d86a152023f71dcafc2d2242b995f2353661e3af8ec85", "size": 56656, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_9_f6229b35d0d2be30498d.mp4"}, {"_type": "video-file", "sha256": "21c3b18aeb0fc202505f14c166f28e908ba3edcfc700f9ab3c15ef71ed9f67a0", "size": 53048, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_9_21c3b18aeb0fc202505f.mp4"}], "captions": false}, "evaluation/sampler_results/policy_reward_min/agent_0": -11.0, "evaluation/sampler_results/policy_reward_min/agent_1": -11.0, "evaluation/sampler_results/policy_reward_min/agent_2": -11.0, "evaluation/sampler_results/policy_reward_max/agent_0": 1.0, "evaluation/sampler_results/policy_reward_max/agent_1": 1.0, "evaluation/sampler_results/policy_reward_max/agent_2": 1.0, "evaluation/sampler_results/policy_reward_mean/agent_0": -8.73, "evaluation/sampler_results/policy_reward_mean/agent_1": -9.92, "evaluation/sampler_results/policy_reward_mean/agent_2": -9.18, "evaluation/sampler_results/sampler_perf/mean_raw_obs_processing_ms": 2.3504840243946417, "evaluation/sampler_results/sampler_perf/mean_inference_ms": 3.8959264755249023, "evaluation/sampler_results/sampler_perf/mean_action_processing_ms": 0.24940924210981893, "evaluation/sampler_results/sampler_perf/mean_env_wait_ms": 0.12068098241632635, "evaluation/sampler_results/sampler_perf/mean_env_render_ms": 0.0, "evaluation/sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.00397793451944987, "evaluation/sampler_results/connector_metrics/StateBufferConnector_ms": 0.0025942325592041016, "evaluation/sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.17690141995747885}
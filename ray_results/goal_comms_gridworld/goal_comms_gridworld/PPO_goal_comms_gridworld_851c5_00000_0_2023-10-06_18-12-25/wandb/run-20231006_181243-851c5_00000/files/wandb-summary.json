{"episode_reward_max": -6.0, "episode_reward_min": -33.0, "episode_reward_mean": -27.957142857142856, "episode_len_mean": 10.982417582417582, "episodes_this_iter": 910, "num_faulty_episodes": 0, "num_healthy_workers": 8, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 15000000, "num_agent_steps_trained": 0, "num_env_steps_sampled": 5000000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 10000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 960.5586867636522, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 5000000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 15000000, "episodes_total": 457381, "training_iteration": 500, "timestamp": 1696618530, "time_this_iter_s": 17.14288878440857, "time_total_s": 5833.50932765007, "time_since_restore": 5833.50932765007, "iterations_since_restore": 500, "info/num_env_steps_sampled": 5000000, "info/num_env_steps_trained": 0, "info/num_agent_steps_sampled": 15000000, "info/num_agent_steps_trained": 0, "sampler_results/episode_reward_max": -6.0, "sampler_results/episode_reward_min": -33.0, "sampler_results/episode_reward_mean": -27.957142857142856, "sampler_results/episode_len_mean": 10.982417582417582, "sampler_results/episodes_this_iter": 910, "sampler_results/num_faulty_episodes": 0, "policy_reward_min/agent_0": -11.0, "policy_reward_min/agent_1": -11.0, "policy_reward_min/agent_2": -11.0, "policy_reward_max/agent_0": 1.0, "policy_reward_max/agent_1": 1.0, "policy_reward_max/agent_2": 1.0, "policy_reward_mean/agent_0": -9.542857142857143, "policy_reward_mean/agent_1": -9.787912087912089, "policy_reward_mean/agent_2": -8.626373626373626, "sampler_perf/mean_raw_obs_processing_ms": 1.631023753301347, "sampler_perf/mean_inference_ms": 4.308839161790696, "sampler_perf/mean_action_processing_ms": 0.28804183892810364, "sampler_perf/mean_env_wait_ms": 0.1395846815247022, "sampler_perf/mean_env_render_ms": 0.0, "connector_metrics/ObsPreprocessorConnector_ms": 0.004805496760777065, "connector_metrics/StateBufferConnector_ms": 0.003106681418506217, "connector_metrics/ViewRequirementAgentConnector_ms": 0.2115053484291384, "timers/training_iteration_time_ms": 10442.023, "timers/sample_time_ms": 8314.672, "timers/synch_weights_time_ms": 11.653, "counters/num_env_steps_sampled": 5000000, "counters/num_env_steps_trained": 0, "counters/num_agent_steps_sampled": 15000000, "counters/num_agent_steps_trained": 0, "perf/cpu_util_percent": 16.80909090909091, "perf/ram_util_percent": 60.86818181818183, "perf/gpu_util_percent0": 0.002272727272727273, "perf/vram_util_percent0": 0.046630859375, "sampler_results/policy_reward_min/agent_0": -11.0, "sampler_results/policy_reward_min/agent_1": -11.0, "sampler_results/policy_reward_min/agent_2": -11.0, "sampler_results/policy_reward_max/agent_0": 1.0, "sampler_results/policy_reward_max/agent_1": 1.0, "sampler_results/policy_reward_max/agent_2": 1.0, "sampler_results/policy_reward_mean/agent_0": -9.542857142857143, "sampler_results/policy_reward_mean/agent_1": -9.787912087912089, "sampler_results/policy_reward_mean/agent_2": -8.626373626373626, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.631023753301347, "sampler_results/sampler_perf/mean_inference_ms": 4.308839161790696, "sampler_results/sampler_perf/mean_action_processing_ms": 0.28804183892810364, "sampler_results/sampler_perf/mean_env_wait_ms": 0.1395846815247022, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.004805496760777065, "sampler_results/connector_metrics/StateBufferConnector_ms": 0.003106681418506217, "sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.2115053484291384, "info/learner/__all__/num_agent_steps_trained": 6144.0, "info/learner/__all__/num_env_steps_trained": 10000.0, "info/learner/__all__/total_loss": 1.0820600390434265, "info/learner/agent_0/total_loss": 1.0820600390434265, "info/learner/agent_0/policy_loss": -0.0006882257759571076, "info/learner/agent_0/vf_loss": 1.269290623664856, "info/learner/agent_0/vf_loss_unclipped": 29.584835844039915, "info/learner/agent_0/vf_explained_var": 0.20427649974822998, "info/learner/agent_0/entropy": 0.6236646795272827, "info/learner/agent_0/mean_kl_loss": 0.021016818080097435, "info/learner/agent_0/default_optimizer_lr": 0.0005, "info/learner/agent_0/curr_lr": 0.0005, "info/learner/agent_0/curr_entropy_coeff": 0.01, "info/learner/agent_0/curr_kl_coeff": 0.0, "info/learner/agent_1/total_loss": 0.23029779732227326, "info/learner/agent_1/policy_loss": -0.01297369409352541, "info/learner/agent_1/vf_loss": 0.9926322388648987, "info/learner/agent_1/vf_loss_unclipped": 29.4475253200531, "info/learner/agent_1/vf_explained_var": 0.1790796422958374, "info/learner/agent_1/entropy": 0.4886570465564728, "info/learner/agent_1/mean_kl_loss": 0.499675407409668, "info/learner/agent_1/default_optimizer_lr": 0.0005, "info/learner/agent_1/curr_lr": 0.0005, "info/learner/agent_1/curr_entropy_coeff": 0.01, "info/learner/agent_1/curr_kl_coeff": 0.0, "info/learner/agent_2/total_loss": 0.5413644659519196, "info/learner/agent_2/policy_loss": -0.002338704615831375, "info/learner/agent_2/vf_loss": 2.19848650932312, "info/learner/agent_2/vf_loss_unclipped": 29.90738910675049, "info/learner/agent_2/vf_explained_var": 0.1337041974067688, "info/learner/agent_2/entropy": 0.5918451130390168, "info/learner/agent_2/mean_kl_loss": 0.005392553568817675, "info/learner/agent_2/default_optimizer_lr": 0.0005, "info/learner/agent_2/curr_lr": 0.0005, "info/learner/agent_2/curr_entropy_coeff": 0.01, "info/learner/agent_2/curr_kl_coeff": 0.0, "_timestamp": 1696618531.0497606, "_runtime": 6167.581747531891, "_step": 499, "evaluation/episode_reward_max": -10.0, "evaluation/episode_reward_min": -33.0, "evaluation/episode_reward_mean": -27.99, "evaluation/episode_len_mean": 11.0, "evaluation/episodes_this_iter": 100, "evaluation/num_faulty_episodes": 0, "evaluation/num_agent_steps_sampled_this_iter": 3300, "evaluation/num_env_steps_sampled_this_iter": 1100, "evaluation/timesteps_this_iter": 1100, "evaluation/num_healthy_workers": 0, "evaluation/num_in_flight_async_reqs": 0, "evaluation/num_remote_worker_restarts": 0, "evaluation/sampler_results/episode_reward_max": -10.0, "evaluation/sampler_results/episode_reward_min": -33.0, "evaluation/sampler_results/episode_reward_mean": -27.99, "evaluation/sampler_results/episode_len_mean": 11.0, "evaluation/sampler_results/episodes_this_iter": 100, "evaluation/sampler_results/num_faulty_episodes": 0, "evaluation/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "2f117e5090c64020c91e87fc7c796cf5ea687ec7632f184b384a009467f4ec5c", "size": 50254, "path": "media/videos/evaluation/episode_media/env_0_video_499_2f117e5090c64020c91e.mp4"}, {"_type": "video-file", "sha256": "8ee19d0fda40f4c0703e962b77a8c64872adfec5c33ad5946db59cff612abaff", "size": 47145, "path": "media/videos/evaluation/episode_media/env_0_video_499_8ee19d0fda40f4c0703e.mp4"}, {"_type": "video-file", "sha256": "eebd9b592097c8e19a1f7591ad2a807564a022eb7bea0c8e74a870fa40f3a41a", "size": 48786, "path": "media/videos/evaluation/episode_media/env_0_video_499_eebd9b592097c8e19a1f.mp4"}, {"_type": "video-file", "sha256": "df739fa3111693c4d873f40a67e8a7c2be7839fc2081210b5bb5a5820aa3f419", "size": 47787, "path": "media/videos/evaluation/episode_media/env_0_video_499_df739fa3111693c4d873.mp4"}, {"_type": "video-file", "sha256": "55b1b59c64c449c44934e5c6bace72f04b4064d832388d440d022ce259b2ac74", "size": 49497, "path": "media/videos/evaluation/episode_media/env_0_video_499_55b1b59c64c449c44934.mp4"}, {"_type": "video-file", "sha256": "b4e540affe22cb051be59aab98893f7a3d5051427434f13f924b9fc8f302fbf0", "size": 49139, "path": "media/videos/evaluation/episode_media/env_0_video_499_b4e540affe22cb051be5.mp4"}], "captions": false}, "evaluation/policy_reward_min/agent_0": -11.0, "evaluation/policy_reward_min/agent_1": -11.0, "evaluation/policy_reward_min/agent_2": -11.0, "evaluation/policy_reward_max/agent_0": 1.0, "evaluation/policy_reward_max/agent_1": 1.0, "evaluation/policy_reward_max/agent_2": 1.0, "evaluation/policy_reward_mean/agent_0": -9.54, "evaluation/policy_reward_mean/agent_1": -9.41, "evaluation/policy_reward_mean/agent_2": -9.04, "evaluation/sampler_perf/mean_raw_obs_processing_ms": 2.206621840594838, "evaluation/sampler_perf/mean_inference_ms": 3.646017147130654, "evaluation/sampler_perf/mean_action_processing_ms": 0.217641685213506, "evaluation/sampler_perf/mean_env_wait_ms": 0.10353470925837, "evaluation/sampler_perf/mean_env_render_ms": 0.0, "evaluation/connector_metrics/ObsPreprocessorConnector_ms": 0.0031665166219075522, "evaluation/connector_metrics/StateBufferConnector_ms": 0.0024399757385253906, "evaluation/connector_metrics/ViewRequirementAgentConnector_ms": 0.16181572278340658, "evaluation/sampler_results/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "2f117e5090c64020c91e87fc7c796cf5ea687ec7632f184b384a009467f4ec5c", "size": 50254, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_499_2f117e5090c64020c91e.mp4"}, {"_type": "video-file", "sha256": "8ee19d0fda40f4c0703e962b77a8c64872adfec5c33ad5946db59cff612abaff", "size": 47145, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_499_8ee19d0fda40f4c0703e.mp4"}, {"_type": "video-file", "sha256": "eebd9b592097c8e19a1f7591ad2a807564a022eb7bea0c8e74a870fa40f3a41a", "size": 48786, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_499_eebd9b592097c8e19a1f.mp4"}, {"_type": "video-file", "sha256": "df739fa3111693c4d873f40a67e8a7c2be7839fc2081210b5bb5a5820aa3f419", "size": 47787, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_499_df739fa3111693c4d873.mp4"}, {"_type": "video-file", "sha256": "55b1b59c64c449c44934e5c6bace72f04b4064d832388d440d022ce259b2ac74", "size": 49497, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_499_55b1b59c64c449c44934.mp4"}, {"_type": "video-file", "sha256": "b4e540affe22cb051be59aab98893f7a3d5051427434f13f924b9fc8f302fbf0", "size": 49139, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_499_b4e540affe22cb051be5.mp4"}], "captions": false}, "evaluation/sampler_results/policy_reward_min/agent_0": -11.0, "evaluation/sampler_results/policy_reward_min/agent_1": -11.0, "evaluation/sampler_results/policy_reward_min/agent_2": -11.0, "evaluation/sampler_results/policy_reward_max/agent_0": 1.0, "evaluation/sampler_results/policy_reward_max/agent_1": 1.0, "evaluation/sampler_results/policy_reward_max/agent_2": 1.0, "evaluation/sampler_results/policy_reward_mean/agent_0": -9.54, "evaluation/sampler_results/policy_reward_mean/agent_1": -9.41, "evaluation/sampler_results/policy_reward_mean/agent_2": -9.04, "evaluation/sampler_results/sampler_perf/mean_raw_obs_processing_ms": 2.206621840594838, "evaluation/sampler_results/sampler_perf/mean_inference_ms": 3.646017147130654, "evaluation/sampler_results/sampler_perf/mean_action_processing_ms": 0.217641685213506, "evaluation/sampler_results/sampler_perf/mean_env_wait_ms": 0.10353470925837, "evaluation/sampler_results/sampler_perf/mean_env_render_ms": 0.0, "evaluation/sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.0031665166219075522, "evaluation/sampler_results/connector_metrics/StateBufferConnector_ms": 0.0024399757385253906, "evaluation/sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.16181572278340658, "_wandb": {"runtime": 6167}}
Failure # 1 (occurred at 2023-09-28_00-38-35)
The actor died because of an error raised in its creation task, [36mray::PPO.__init__()[39m (pid=18341, ip=172.17.137.197, actor_id=4027c4cfd75ca38fc10508e201000000, repr=PPO)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/worker_set.py", line 227, in _setup
    self.add_workers(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/worker_set.py", line 593, in add_workers
    raise result.get()
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/utils/actor_manager.py", line 481, in __fetch_result
    result = ray.get(r)
ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, [36mray::RolloutWorker.__init__()[39m (pid=18490, ip=172.17.137.197, actor_id=4b7d3645073e337e0988983901000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f00d1e94af0>)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 525, in __init__
    self._update_policy_map(policy_dict=self.policy_dict)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 1727, in _update_policy_map
    self._build_policy_map(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 1838, in _build_policy_map
    new_policy = create_policy_for_framework(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/utils/policy.py", line 142, in create_policy_for_framework
    return policy_class(observation_space, action_space, merged_config)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/ppo/ppo_torch_policy.py", line 49, in __init__
    TorchPolicyV2.__init__(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/policy/torch_policy_v2.py", line 92, in __init__
    model = self.make_rl_module()
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/policy/policy.py", line 424, in make_rl_module
    marl_module = marl_spec.build()
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/core/rl_module/marl_module.py", line 462, in build
    module = self.marl_module_class(module_config)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/core/rl_module/rl_module.py", line 377, in new_init
    previous_init(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/core/rl_module/rl_module.py", line 377, in new_init
    previous_init(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/core/rl_module/marl_module.py", line 58, in __init__
    super().__init__(config or MultiAgentRLModuleConfig())
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/core/rl_module/rl_module.py", line 369, in __init__
    self.setup()
  File "/home/dylan/projects/lang-acq/jtc/macrl/simple_macrl.py", line 101, in setup
    self.encoding_dim = module_0.get_output_specs()[ENCODER_OUT].shape[-1]
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1265, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'PPOTorchRLModule' object has no attribute 'get_output_specs'

During handling of the above exception, another exception occurred:

[36mray::PPO.__init__()[39m (pid=18341, ip=172.17.137.197, actor_id=4027c4cfd75ca38fc10508e201000000, repr=PPO)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/algorithm.py", line 517, in __init__
    super().__init__(
  File "/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py", line 185, in __init__
    self.setup(copy.deepcopy(self.config))
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/algorithm.py", line 639, in setup
    self.workers = WorkerSet(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/worker_set.py", line 179, in __init__
    raise e.args[0].args[2]
AttributeError: 'PPOTorchRLModule' object has no attribute 'get_output_specs'

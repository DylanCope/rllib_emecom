{"episode_reward_max": 1.0, "episode_reward_min": -33.0, "episode_reward_mean": -27.339168490153174, "episode_len_mean": 10.946389496717725, "episodes_this_iter": 914, "num_faulty_episodes": 0, "num_healthy_workers": 8, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 15000000, "num_agent_steps_trained": 0, "num_env_steps_sampled": 5000000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 10000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 319.3862648076566, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 5000000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 15000000, "episodes_total": 456202, "training_iteration": 500, "timestamp": 1696342790, "time_this_iter_s": 38.139328956604004, "time_total_s": 16266.364953756332, "time_since_restore": 16266.364953756332, "iterations_since_restore": 500, "info/num_env_steps_sampled": 5000000, "info/num_env_steps_trained": 0, "info/num_agent_steps_sampled": 15000000, "info/num_agent_steps_trained": 0, "sampler_results/episode_reward_max": 1.0, "sampler_results/episode_reward_min": -33.0, "sampler_results/episode_reward_mean": -27.339168490153174, "sampler_results/episode_len_mean": 10.946389496717725, "sampler_results/episodes_this_iter": 914, "sampler_results/num_faulty_episodes": 0, "policy_reward_min/agent_0": -11.0, "policy_reward_min/agent_1": -11.0, "policy_reward_min/agent_2": -11.0, "policy_reward_max/agent_0": 1.0, "policy_reward_max/agent_1": 1.0, "policy_reward_max/agent_2": 1.0, "policy_reward_mean/agent_0": -9.096280087527353, "policy_reward_mean/agent_1": -9.088621444201314, "policy_reward_mean/agent_2": -9.154266958424508, "sampler_perf/mean_raw_obs_processing_ms": 1.663774813512262, "sampler_perf/mean_inference_ms": 3.945679598862518, "sampler_perf/mean_action_processing_ms": 0.31053614571967414, "sampler_perf/mean_env_wait_ms": 0.15265747838937635, "sampler_perf/mean_env_render_ms": 0.0, "connector_metrics/ObsPreprocessorConnector_ms": 0.0054837316600707744, "connector_metrics/StateBufferConnector_ms": 0.0034452006383849966, "connector_metrics/ViewRequirementAgentConnector_ms": 0.22689030172179686, "timers/training_iteration_time_ms": 30932.041, "timers/sample_time_ms": 7795.022, "timers/synch_weights_time_ms": 4.95, "counters/num_env_steps_sampled": 5000000, "counters/num_env_steps_trained": 0, "counters/num_agent_steps_sampled": 15000000, "counters/num_agent_steps_trained": 0, "perf/cpu_util_percent": 11.825531914893617, "perf/ram_util_percent": 79.42978723404258, "perf/gpu_util_percent0": 0.16829787234042556, "perf/vram_util_percent0": 0.22319647606382978, "sampler_results/policy_reward_min/agent_0": -11.0, "sampler_results/policy_reward_min/agent_1": -11.0, "sampler_results/policy_reward_min/agent_2": -11.0, "sampler_results/policy_reward_max/agent_0": 1.0, "sampler_results/policy_reward_max/agent_1": 1.0, "sampler_results/policy_reward_max/agent_2": 1.0, "sampler_results/policy_reward_mean/agent_0": -9.096280087527353, "sampler_results/policy_reward_mean/agent_1": -9.088621444201314, "sampler_results/policy_reward_mean/agent_2": -9.154266958424508, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.663774813512262, "sampler_results/sampler_perf/mean_inference_ms": 3.945679598862518, "sampler_results/sampler_perf/mean_action_processing_ms": 0.31053614571967414, "sampler_results/sampler_perf/mean_env_wait_ms": 0.15265747838937635, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.0054837316600707744, "sampler_results/connector_metrics/StateBufferConnector_ms": 0.0034452006383849966, "sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.22689030172179686, "info/learner/__all__/num_agent_steps_trained": 6144.0, "info/learner/__all__/num_env_steps_trained": 10000.0, "info/learner/__all__/total_loss": 5.373867668683016, "info/learner/agent_0/total_loss": 5.373867668683016, "info/learner/agent_0/policy_loss": -0.0037898056598120854, "info/learner/agent_0/vf_loss": 1.81020088739033, "info/learner/agent_0/vf_loss_unclipped": 91.18400794644899, "info/learner/agent_0/vf_explained_var": 0.9999989791761471, "info/learner/agent_0/entropy": 1.371718086773836, "info/learner/agent_0/mean_kl_loss": 0.011844347613054819, "info/learner/agent_0/default_optimizer_lr": 0.0005000000000000001, "info/learner/agent_0/curr_lr": 0.0005, "info/learner/agent_0/curr_entropy_coeff": 0.01, "info/learner/agent_0/curr_kl_coeff": 0.0, "info/learner/agent_1/total_loss": 1.8350160227546208, "info/learner/agent_1/policy_loss": -0.002551391909394083, "info/learner/agent_1/vf_loss": 1.8514131428320197, "info/learner/agent_1/vf_loss_unclipped": 91.03826182401633, "info/learner/agent_1/vf_explained_var": 0.9999989489965802, "info/learner/agent_1/entropy": 1.3845737568939789, "info/learner/agent_1/mean_kl_loss": 0.009819920383109358, "info/learner/agent_1/default_optimizer_lr": 0.0005000000000000001, "info/learner/agent_1/curr_lr": 0.0005, "info/learner/agent_1/curr_entropy_coeff": 0.01, "info/learner/agent_1/curr_kl_coeff": 0.0, "info/learner/agent_2/total_loss": 1.7461577487897268, "info/learner/agent_2/policy_loss": -0.0027862095430234, "info/learner/agent_2/vf_loss": 1.7626114736629437, "info/learner/agent_2/vf_loss_unclipped": 91.79286425626731, "info/learner/agent_2/vf_explained_var": 0.9999989867210388, "info/learner/agent_2/entropy": 1.3667515078677406, "info/learner/agent_2/mean_kl_loss": 0.010001249554712743, "info/learner/agent_2/default_optimizer_lr": 0.0005000000000000001, "info/learner/agent_2/curr_lr": 0.0005, "info/learner/agent_2/curr_entropy_coeff": 0.01, "info/learner/agent_2/curr_kl_coeff": 0.0, "_timestamp": 1696342790.7545614, "_runtime": 16451.760098457336, "_step": 499, "evaluation/episode_reward_max": -11.0, "evaluation/episode_reward_min": -33.0, "evaluation/episode_reward_mean": -28.74, "evaluation/episode_len_mean": 10.96, "evaluation/episodes_this_iter": 100, "evaluation/num_faulty_episodes": 0, "evaluation/num_agent_steps_sampled_this_iter": 3288, "evaluation/num_env_steps_sampled_this_iter": 1096, "evaluation/timesteps_this_iter": 1096, "evaluation/num_healthy_workers": 0, "evaluation/num_in_flight_async_reqs": 0, "evaluation/num_remote_worker_restarts": 0, "evaluation/sampler_results/episode_reward_max": -11.0, "evaluation/sampler_results/episode_reward_min": -33.0, "evaluation/sampler_results/episode_reward_mean": -28.74, "evaluation/sampler_results/episode_len_mean": 10.96, "evaluation/sampler_results/episodes_this_iter": 100, "evaluation/sampler_results/num_faulty_episodes": 0, "evaluation/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "91cef8fb60351d7147566de1bf8d3fb72ed5ad8cbfe5cac8ce09a677f7c8dc6d", "size": 63764, "path": "media/videos/evaluation/episode_media/env_0_video_499_91cef8fb60351d714756.mp4"}, {"_type": "video-file", "sha256": "fea1a639879ef352933eadac79c4aaeaf90f2478aab24c8ef9abc9ce6e8ddd55", "size": 58370, "path": "media/videos/evaluation/episode_media/env_0_video_499_fea1a639879ef352933e.mp4"}, {"_type": "video-file", "sha256": "c1dc3e0e69403cba89d3f919747553ded0ea63267922f8fa7e52249eeaf82674", "size": 61542, "path": "media/videos/evaluation/episode_media/env_0_video_499_c1dc3e0e69403cba89d3.mp4"}, {"_type": "video-file", "sha256": "e310b029146cf7badd4a22458e37d1359ea350dd42e602396842725a351b05f5", "size": 64613, "path": "media/videos/evaluation/episode_media/env_0_video_499_e310b029146cf7badd4a.mp4"}, {"_type": "video-file", "sha256": "e95086cfb337c09bdedaccbd5961f71cb8f096cd861caee38f0bdd53143cc775", "size": 61549, "path": "media/videos/evaluation/episode_media/env_0_video_499_e95086cfb337c09bdeda.mp4"}, {"_type": "video-file", "sha256": "2a181a5d557ab5cb0388bcd2800f7d0aeda825dda46b5f33ca566cb40a209abf", "size": 60399, "path": "media/videos/evaluation/episode_media/env_0_video_499_2a181a5d557ab5cb0388.mp4"}], "captions": false}, "evaluation/policy_reward_min/agent_0": -11.0, "evaluation/policy_reward_min/agent_1": -11.0, "evaluation/policy_reward_min/agent_2": -11.0, "evaluation/policy_reward_max/agent_0": 0.0, "evaluation/policy_reward_max/agent_1": 0.0, "evaluation/policy_reward_max/agent_2": 1.0, "evaluation/policy_reward_mean/agent_0": -9.61, "evaluation/policy_reward_mean/agent_1": -9.59, "evaluation/policy_reward_mean/agent_2": -9.54, "evaluation/sampler_perf/mean_raw_obs_processing_ms": 2.5090768626726008, "evaluation/sampler_perf/mean_inference_ms": 3.3839450664802637, "evaluation/sampler_perf/mean_action_processing_ms": 0.2665592921250455, "evaluation/sampler_perf/mean_env_wait_ms": 0.13016978060355486, "evaluation/sampler_perf/mean_env_render_ms": 0.0, "evaluation/connector_metrics/ObsPreprocessorConnector_ms": 0.00455474853515625, "evaluation/connector_metrics/StateBufferConnector_ms": 0.0027649402618408203, "evaluation/connector_metrics/ViewRequirementAgentConnector_ms": 0.19099346796671549, "evaluation/sampler_results/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "91cef8fb60351d7147566de1bf8d3fb72ed5ad8cbfe5cac8ce09a677f7c8dc6d", "size": 63764, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_499_91cef8fb60351d714756.mp4"}, {"_type": "video-file", "sha256": "fea1a639879ef352933eadac79c4aaeaf90f2478aab24c8ef9abc9ce6e8ddd55", "size": 58370, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_499_fea1a639879ef352933e.mp4"}, {"_type": "video-file", "sha256": "c1dc3e0e69403cba89d3f919747553ded0ea63267922f8fa7e52249eeaf82674", "size": 61542, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_499_c1dc3e0e69403cba89d3.mp4"}, {"_type": "video-file", "sha256": "e310b029146cf7badd4a22458e37d1359ea350dd42e602396842725a351b05f5", "size": 64613, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_499_e310b029146cf7badd4a.mp4"}, {"_type": "video-file", "sha256": "e95086cfb337c09bdedaccbd5961f71cb8f096cd861caee38f0bdd53143cc775", "size": 61549, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_499_e95086cfb337c09bdeda.mp4"}, {"_type": "video-file", "sha256": "2a181a5d557ab5cb0388bcd2800f7d0aeda825dda46b5f33ca566cb40a209abf", "size": 60399, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_499_2a181a5d557ab5cb0388.mp4"}], "captions": false}, "evaluation/sampler_results/policy_reward_min/agent_0": -11.0, "evaluation/sampler_results/policy_reward_min/agent_1": -11.0, "evaluation/sampler_results/policy_reward_min/agent_2": -11.0, "evaluation/sampler_results/policy_reward_max/agent_0": 0.0, "evaluation/sampler_results/policy_reward_max/agent_1": 0.0, "evaluation/sampler_results/policy_reward_max/agent_2": 1.0, "evaluation/sampler_results/policy_reward_mean/agent_0": -9.61, "evaluation/sampler_results/policy_reward_mean/agent_1": -9.59, "evaluation/sampler_results/policy_reward_mean/agent_2": -9.54, "evaluation/sampler_results/sampler_perf/mean_raw_obs_processing_ms": 2.5090768626726008, "evaluation/sampler_results/sampler_perf/mean_inference_ms": 3.3839450664802637, "evaluation/sampler_results/sampler_perf/mean_action_processing_ms": 0.2665592921250455, "evaluation/sampler_results/sampler_perf/mean_env_wait_ms": 0.13016978060355486, "evaluation/sampler_results/sampler_perf/mean_env_render_ms": 0.0, "evaluation/sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.00455474853515625, "evaluation/sampler_results/connector_metrics/StateBufferConnector_ms": 0.0027649402618408203, "evaluation/sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.19099346796671549, "_wandb": {"runtime": 16451}}
{"episode_reward_max": 3.0, "episode_reward_min": -14.0, "episode_reward_mean": -3.81945090739879, "episode_len_mean": 4.65658445788739, "episodes_this_iter": 2149, "num_faulty_episodes": 0, "num_healthy_workers": 8, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3150000, "num_agent_steps_trained": 0, "num_env_steps_sampled": 1050000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 10000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 888.6567710303635, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 1050000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 3150000, "episodes_total": 208651, "training_iteration": 105, "timestamp": 1696612208, "time_this_iter_s": 11.524879217147827, "time_total_s": 1199.8768005371094, "time_since_restore": 1199.8768005371094, "iterations_since_restore": 105, "info/num_env_steps_sampled": 1050000, "info/num_env_steps_trained": 0, "info/num_agent_steps_sampled": 3150000, "info/num_agent_steps_trained": 0, "sampler_results/episode_reward_max": 3.0, "sampler_results/episode_reward_min": -14.0, "sampler_results/episode_reward_mean": -3.81945090739879, "sampler_results/episode_len_mean": 4.65658445788739, "sampler_results/episodes_this_iter": 2149, "sampler_results/num_faulty_episodes": 0, "policy_reward_min/agent_0": -6.0, "policy_reward_min/agent_1": -6.0, "policy_reward_min/agent_2": -7.0, "policy_reward_max/agent_0": 1.0, "policy_reward_max/agent_1": 1.0, "policy_reward_max/agent_2": 1.0, "policy_reward_mean/agent_0": -1.2563983248022337, "policy_reward_mean/agent_1": -1.281991624011168, "policy_reward_mean/agent_2": -1.2810609585853885, "sampler_perf/mean_raw_obs_processing_ms": 1.7533155780228116, "sampler_perf/mean_inference_ms": 4.329357164160994, "sampler_perf/mean_action_processing_ms": 0.28651164459556355, "sampler_perf/mean_env_wait_ms": 0.141901517518015, "sampler_perf/mean_env_render_ms": 0.0, "connector_metrics/ObsPreprocessorConnector_ms": 0.00537504276342497, "connector_metrics/StateBufferConnector_ms": 0.007962233820164205, "connector_metrics/ViewRequirementAgentConnector_ms": 0.23187122475144956, "timers/training_iteration_time_ms": 10897.274, "timers/sample_time_ms": 8743.646, "timers/synch_weights_time_ms": 11.568, "counters/num_env_steps_sampled": 1050000, "counters/num_env_steps_trained": 0, "counters/num_agent_steps_sampled": 3150000, "counters/num_agent_steps_trained": 0, "perf/cpu_util_percent": 27.200000000000003, "perf/ram_util_percent": 57.6625, "perf/gpu_util_percent0": 0.00125, "perf/vram_util_percent0": 0.042292277018229164, "sampler_results/policy_reward_min/agent_0": -6.0, "sampler_results/policy_reward_min/agent_1": -6.0, "sampler_results/policy_reward_min/agent_2": -7.0, "sampler_results/policy_reward_max/agent_0": 1.0, "sampler_results/policy_reward_max/agent_1": 1.0, "sampler_results/policy_reward_max/agent_2": 1.0, "sampler_results/policy_reward_mean/agent_0": -1.2563983248022337, "sampler_results/policy_reward_mean/agent_1": -1.281991624011168, "sampler_results/policy_reward_mean/agent_2": -1.2810609585853885, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.7533155780228116, "sampler_results/sampler_perf/mean_inference_ms": 4.329357164160994, "sampler_results/sampler_perf/mean_action_processing_ms": 0.28651164459556355, "sampler_results/sampler_perf/mean_env_wait_ms": 0.141901517518015, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.00537504276342497, "sampler_results/connector_metrics/StateBufferConnector_ms": 0.007962233820164205, "sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.23187122475144956, "info/learner/__all__/num_agent_steps_trained": 6144.0, "info/learner/__all__/num_env_steps_trained": 10000.0, "info/learner/__all__/total_loss": 2.5018670177459716, "info/learner/agent_0/total_loss": 2.5018670177459716, "info/learner/agent_0/policy_loss": -0.004630797263234854, "info/learner/agent_0/vf_loss": 0.05408117651939392, "info/learner/agent_0/vf_loss_unclipped": 0.05408117651939392, "info/learner/agent_0/vf_explained_var": 0.9643228101730347, "info/learner/agent_0/entropy": 0.4178531157970429, "info/learner/agent_0/mean_kl_loss": 0.02809759058058262, "info/learner/agent_0/default_optimizer_lr": 0.0005, "info/learner/agent_0/curr_lr": 0.0005, "info/learner/agent_0/curr_entropy_coeff": 0.01, "info/learner/agent_0/curr_kl_coeff": 0.0, "info/learner/agent_1/total_loss": 0.006992049142718315, "info/learner/agent_1/policy_loss": -0.00132330521941185, "info/learner/agent_1/vf_loss": 0.052791398614645005, "info/learner/agent_1/vf_loss_unclipped": 0.052791398614645005, "info/learner/agent_1/vf_explained_var": 0.9662850952148437, "info/learner/agent_1/entropy": 0.4882494926452637, "info/learner/agent_1/mean_kl_loss": 0.008850292526185513, "info/learner/agent_1/default_optimizer_lr": 0.0005, "info/learner/agent_1/curr_lr": 0.0005, "info/learner/agent_1/curr_entropy_coeff": 0.01, "info/learner/agent_1/curr_kl_coeff": 0.0, "info/learner/agent_2/total_loss": 2.4901639938354494, "info/learner/agent_2/policy_loss": -0.004487365912646055, "info/learner/agent_2/vf_loss": 9.990603218078613, "info/learner/agent_2/vf_loss_unclipped": 768.6331982421875, "info/learner/agent_2/vf_explained_var": -0.44270967960357666, "info/learner/agent_2/entropy": 0.29994874835014346, "info/learner/agent_2/mean_kl_loss": 0.005786990588530898, "info/learner/agent_2/default_optimizer_lr": 0.0005, "info/learner/agent_2/curr_lr": 0.0005, "info/learner/agent_2/curr_entropy_coeff": 0.01, "info/learner/agent_2/curr_kl_coeff": 0.0, "_timestamp": 1696612208.1689577, "_runtime": 1242.8863236904144, "_step": 104, "evaluation/episode_reward_max": 2.0, "evaluation/episode_reward_min": -12.0, "evaluation/episode_reward_mean": -3.43, "evaluation/episode_len_mean": 4.56, "evaluation/episodes_this_iter": 100, "evaluation/num_faulty_episodes": 0, "evaluation/num_agent_steps_sampled_this_iter": 1368, "evaluation/num_env_steps_sampled_this_iter": 456, "evaluation/timesteps_this_iter": 456, "evaluation/num_healthy_workers": 0, "evaluation/num_in_flight_async_reqs": 0, "evaluation/num_remote_worker_restarts": 0, "evaluation/sampler_results/episode_reward_max": 2.0, "evaluation/sampler_results/episode_reward_min": -12.0, "evaluation/sampler_results/episode_reward_mean": -3.43, "evaluation/sampler_results/episode_len_mean": 4.56, "evaluation/sampler_results/episodes_this_iter": 100, "evaluation/sampler_results/num_faulty_episodes": 0, "evaluation/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "c9e43442625059df55c365dc629fba7b90d1940c2e9744ef1a838f442bd70319", "size": 35973, "path": "media/videos/evaluation/episode_media/env_0_video_99_c9e43442625059df55c3.mp4"}, {"_type": "video-file", "sha256": "82801cbc75b05750901313a96ebfad69605b5ee08df065e824e7aa4abad7c7e9", "size": 34440, "path": "media/videos/evaluation/episode_media/env_0_video_99_82801cbc75b057509013.mp4"}, {"_type": "video-file", "sha256": "85e20a6c8ba14256e62a331c7b0ff7cb4fd9a2486e0daeac50d5babbbb9257ba", "size": 36411, "path": "media/videos/evaluation/episode_media/env_0_video_99_85e20a6c8ba14256e62a.mp4"}, {"_type": "video-file", "sha256": "b183544c76f35fe3347d156c18cb689530cce2049d14efd72c09d3a6d76feac3", "size": 30816, "path": "media/videos/evaluation/episode_media/env_0_video_99_b183544c76f35fe3347d.mp4"}, {"_type": "video-file", "sha256": "178c82290934f85a3010e1396248996db295f5594b91c0640fb3c66864cad159", "size": 32980, "path": "media/videos/evaluation/episode_media/env_0_video_99_178c82290934f85a3010.mp4"}, {"_type": "video-file", "sha256": "01e8af048057277c04e74e63607cc557de8ebb8dcce26d6d5644d27a4dfb645e", "size": 33684, "path": "media/videos/evaluation/episode_media/env_0_video_99_01e8af048057277c04e7.mp4"}], "captions": false}, "evaluation/policy_reward_min/agent_0": -5.0, "evaluation/policy_reward_min/agent_1": -5.0, "evaluation/policy_reward_min/agent_2": -7.0, "evaluation/policy_reward_max/agent_0": 1.0, "evaluation/policy_reward_max/agent_1": 1.0, "evaluation/policy_reward_max/agent_2": 1.0, "evaluation/policy_reward_mean/agent_0": -1.11, "evaluation/policy_reward_mean/agent_1": -1.16, "evaluation/policy_reward_mean/agent_2": -1.16, "evaluation/sampler_perf/mean_raw_obs_processing_ms": 3.236531596091022, "evaluation/sampler_perf/mean_inference_ms": 3.680122329300005, "evaluation/sampler_perf/mean_action_processing_ms": 0.21894662424703124, "evaluation/sampler_perf/mean_env_wait_ms": 0.1053859809884574, "evaluation/sampler_perf/mean_env_render_ms": 0.0, "evaluation/connector_metrics/ObsPreprocessorConnector_ms": 0.0035784244537353516, "evaluation/connector_metrics/StateBufferConnector_ms": 0.006119728088378906, "evaluation/connector_metrics/ViewRequirementAgentConnector_ms": 0.1739199161529541, "evaluation/sampler_results/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "c9e43442625059df55c365dc629fba7b90d1940c2e9744ef1a838f442bd70319", "size": 35973, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_99_c9e43442625059df55c3.mp4"}, {"_type": "video-file", "sha256": "82801cbc75b05750901313a96ebfad69605b5ee08df065e824e7aa4abad7c7e9", "size": 34440, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_99_82801cbc75b057509013.mp4"}, {"_type": "video-file", "sha256": "85e20a6c8ba14256e62a331c7b0ff7cb4fd9a2486e0daeac50d5babbbb9257ba", "size": 36411, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_99_85e20a6c8ba14256e62a.mp4"}, {"_type": "video-file", "sha256": "b183544c76f35fe3347d156c18cb689530cce2049d14efd72c09d3a6d76feac3", "size": 30816, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_99_b183544c76f35fe3347d.mp4"}, {"_type": "video-file", "sha256": "178c82290934f85a3010e1396248996db295f5594b91c0640fb3c66864cad159", "size": 32980, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_99_178c82290934f85a3010.mp4"}, {"_type": "video-file", "sha256": "01e8af048057277c04e74e63607cc557de8ebb8dcce26d6d5644d27a4dfb645e", "size": 33684, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_99_01e8af048057277c04e7.mp4"}], "captions": false}, "evaluation/sampler_results/policy_reward_min/agent_0": -5.0, "evaluation/sampler_results/policy_reward_min/agent_1": -5.0, "evaluation/sampler_results/policy_reward_min/agent_2": -7.0, "evaluation/sampler_results/policy_reward_max/agent_0": 1.0, "evaluation/sampler_results/policy_reward_max/agent_1": 1.0, "evaluation/sampler_results/policy_reward_max/agent_2": 1.0, "evaluation/sampler_results/policy_reward_mean/agent_0": -1.11, "evaluation/sampler_results/policy_reward_mean/agent_1": -1.16, "evaluation/sampler_results/policy_reward_mean/agent_2": -1.16, "evaluation/sampler_results/sampler_perf/mean_raw_obs_processing_ms": 3.236531596091022, "evaluation/sampler_results/sampler_perf/mean_inference_ms": 3.680122329300005, "evaluation/sampler_results/sampler_perf/mean_action_processing_ms": 0.21894662424703124, "evaluation/sampler_results/sampler_perf/mean_env_wait_ms": 0.1053859809884574, "evaluation/sampler_results/sampler_perf/mean_env_render_ms": 0.0, "evaluation/sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.0035784244537353516, "evaluation/sampler_results/connector_metrics/StateBufferConnector_ms": 0.006119728088378906, "evaluation/sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.1739199161529541}
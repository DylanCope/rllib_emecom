{"episode_reward_max": 3.0, "episode_reward_min": -33.0, "episode_reward_mean": -14.498627630375115, "episode_len_mean": 9.16651418115279, "episodes_this_iter": 1093, "num_faulty_episodes": 0, "num_healthy_workers": 8, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 0, "num_env_steps_sampled": 80000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 10000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 1006.7210923913123, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 80000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 240000, "episodes_total": 7620, "training_iteration": 8, "timestamp": 1696523954, "time_this_iter_s": 9.954864263534546, "time_total_s": 84.56357908248901, "time_since_restore": 84.56357908248901, "iterations_since_restore": 8, "info/num_env_steps_sampled": 80000, "info/num_env_steps_trained": 0, "info/num_agent_steps_sampled": 240000, "info/num_agent_steps_trained": 0, "sampler_results/episode_reward_max": 3.0, "sampler_results/episode_reward_min": -33.0, "sampler_results/episode_reward_mean": -14.498627630375115, "sampler_results/episode_len_mean": 9.16651418115279, "sampler_results/episodes_this_iter": 1093, "sampler_results/num_faulty_episodes": 0, "policy_reward_min/agent_0": -11.0, "policy_reward_min/agent_1": -11.0, "policy_reward_min/agent_2": -11.0, "policy_reward_max/agent_0": 1.0, "policy_reward_max/agent_1": 1.0, "policy_reward_max/agent_2": 1.0, "policy_reward_mean/agent_0": -4.962488563586459, "policy_reward_mean/agent_1": -4.605672461116194, "policy_reward_mean/agent_2": -4.9304666056724615, "sampler_perf/mean_raw_obs_processing_ms": 1.6190860773254716, "sampler_perf/mean_inference_ms": 4.410749586134076, "sampler_perf/mean_action_processing_ms": 0.2910567448526857, "sampler_perf/mean_env_wait_ms": 0.1442315939336892, "sampler_perf/mean_env_render_ms": 0.0, "connector_metrics/ObsPreprocessorConnector_ms": 0.004953587698696517, "connector_metrics/StateBufferConnector_ms": 0.004412205199636894, "connector_metrics/ViewRequirementAgentConnector_ms": 0.20692542617951418, "timers/training_iteration_time_ms": 10283.322, "timers/sample_time_ms": 8540.982, "timers/synch_weights_time_ms": 11.624, "counters/num_env_steps_sampled": 80000, "counters/num_env_steps_trained": 0, "counters/num_agent_steps_sampled": 240000, "counters/num_agent_steps_trained": 0, "perf/cpu_util_percent": 23.723076923076924, "perf/ram_util_percent": 62.5, "perf/gpu_util_percent0": 0.023076923076923075, "perf/vram_util_percent0": 0.07569611378205127, "sampler_results/policy_reward_min/agent_0": -11.0, "sampler_results/policy_reward_min/agent_1": -11.0, "sampler_results/policy_reward_min/agent_2": -11.0, "sampler_results/policy_reward_max/agent_0": 1.0, "sampler_results/policy_reward_max/agent_1": 1.0, "sampler_results/policy_reward_max/agent_2": 1.0, "sampler_results/policy_reward_mean/agent_0": -4.962488563586459, "sampler_results/policy_reward_mean/agent_1": -4.605672461116194, "sampler_results/policy_reward_mean/agent_2": -4.9304666056724615, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.6190860773254716, "sampler_results/sampler_perf/mean_inference_ms": 4.410749586134076, "sampler_results/sampler_perf/mean_action_processing_ms": 0.2910567448526857, "sampler_results/sampler_perf/mean_env_wait_ms": 0.1442315939336892, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.004953587698696517, "sampler_results/connector_metrics/StateBufferConnector_ms": 0.004412205199636894, "sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.20692542617951418, "info/learner/__all__/num_agent_steps_trained": 6144.0, "info/learner/__all__/num_env_steps_trained": 10000.0, "info/learner/__all__/total_loss": 5.265228748321533, "info/learner/agent_0/total_loss": 5.265228748321533, "info/learner/agent_0/policy_loss": -0.012170798117294908, "info/learner/agent_0/vf_loss": 7.252462844848633, "info/learner/agent_0/vf_loss_unclipped": 148.4005389404297, "info/learner/agent_0/vf_explained_var": 0.00878790855407715, "info/learner/agent_0/entropy": 1.2808681058883666, "info/learner/agent_0/mean_kl_loss": 0.01006720629717165, "info/learner/agent_0/default_optimizer_lr": 0.0005, "info/learner/agent_0/curr_lr": 0.0005, "info/learner/agent_0/curr_entropy_coeff": 0.01, "info/learner/agent_0/curr_kl_coeff": 0.0, "info/learner/agent_1/total_loss": 1.7038405275344848, "info/learner/agent_1/policy_loss": -0.011636805739253759, "info/learner/agent_1/vf_loss": 6.912354888916016, "info/learner/agent_1/vf_loss_unclipped": 85.63015411376954, "info/learner/agent_1/vf_explained_var": -0.006594738960266113, "info/learner/agent_1/entropy": 1.2611352109909058, "info/learner/agent_1/mean_kl_loss": 0.00997641673857288, "info/learner/agent_1/default_optimizer_lr": 0.0005, "info/learner/agent_1/curr_lr": 0.0005, "info/learner/agent_1/curr_entropy_coeff": 0.01, "info/learner/agent_1/curr_kl_coeff": 0.0, "info/learner/agent_2/total_loss": 1.7732520484924317, "info/learner/agent_2/policy_loss": -0.013768491633236409, "info/learner/agent_2/vf_loss": 7.198883037567139, "info/learner/agent_2/vf_loss_unclipped": 127.5568618774414, "info/learner/agent_2/vf_explained_var": 0.0013618850708007812, "info/learner/agent_2/entropy": 1.2700184202194214, "info/learner/agent_2/mean_kl_loss": 0.011193402730350499, "info/learner/agent_2/default_optimizer_lr": 0.0005, "info/learner/agent_2/curr_lr": 0.0005, "info/learner/agent_2/curr_entropy_coeff": 0.01, "info/learner/agent_2/curr_kl_coeff": 0.0, "_timestamp": 1696523954.3659437, "_runtime": 99.07662868499756, "_step": 7}
{"episode_reward_max": -3.0, "episode_reward_min": -33.0, "episode_reward_mean": -27.835886214442013, "episode_len_mean": 10.960612691466084, "episodes_this_iter": 914, "num_faulty_episodes": 0, "num_healthy_workers": 8, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 5220000, "num_agent_steps_trained": 0, "num_env_steps_sampled": 1740000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 10000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 986.2150577399526, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 1740000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 5220000, "episodes_total": 158603, "training_iteration": 174, "timestamp": 1696522721, "time_this_iter_s": 10.159106731414795, "time_total_s": 1922.409852027893, "time_since_restore": 1922.409852027893, "iterations_since_restore": 174, "info/num_env_steps_sampled": 1740000, "info/num_env_steps_trained": 0, "info/num_agent_steps_sampled": 5220000, "info/num_agent_steps_trained": 0, "sampler_results/episode_reward_max": -3.0, "sampler_results/episode_reward_min": -33.0, "sampler_results/episode_reward_mean": -27.835886214442013, "sampler_results/episode_len_mean": 10.960612691466084, "sampler_results/episodes_this_iter": 914, "sampler_results/num_faulty_episodes": 0, "policy_reward_min/agent_0": -11.0, "policy_reward_min/agent_1": -11.0, "policy_reward_min/agent_2": -11.0, "policy_reward_max/agent_0": 1.0, "policy_reward_max/agent_1": 1.0, "policy_reward_max/agent_2": 1.0, "policy_reward_mean/agent_0": -9.153172866520787, "policy_reward_mean/agent_1": -9.266958424507658, "policy_reward_mean/agent_2": -9.415754923413568, "sampler_perf/mean_raw_obs_processing_ms": 1.5768847329852704, "sampler_perf/mean_inference_ms": 4.251333583330681, "sampler_perf/mean_action_processing_ms": 0.2805626093517101, "sampler_perf/mean_env_wait_ms": 0.13953862441334378, "sampler_perf/mean_env_render_ms": 0.0, "connector_metrics/ObsPreprocessorConnector_ms": 0.005035301266926905, "connector_metrics/StateBufferConnector_ms": 0.0031939133686535903, "connector_metrics/ViewRequirementAgentConnector_ms": 0.20549338199551484, "timers/training_iteration_time_ms": 10613.883, "timers/sample_time_ms": 8543.176, "timers/synch_weights_time_ms": 11.989, "counters/num_env_steps_sampled": 1740000, "counters/num_env_steps_trained": 0, "counters/num_agent_steps_sampled": 5220000, "counters/num_agent_steps_trained": 0, "perf/cpu_util_percent": 24.046153846153842, "perf/ram_util_percent": 64.77692307692308, "perf/gpu_util_percent0": 0.030000000000000002, "perf/vram_util_percent0": 0.07418744991987179, "sampler_results/policy_reward_min/agent_0": -11.0, "sampler_results/policy_reward_min/agent_1": -11.0, "sampler_results/policy_reward_min/agent_2": -11.0, "sampler_results/policy_reward_max/agent_0": 1.0, "sampler_results/policy_reward_max/agent_1": 1.0, "sampler_results/policy_reward_max/agent_2": 1.0, "sampler_results/policy_reward_mean/agent_0": -9.153172866520787, "sampler_results/policy_reward_mean/agent_1": -9.266958424507658, "sampler_results/policy_reward_mean/agent_2": -9.415754923413568, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.5768847329852704, "sampler_results/sampler_perf/mean_inference_ms": 4.251333583330681, "sampler_results/sampler_perf/mean_action_processing_ms": 0.2805626093517101, "sampler_results/sampler_perf/mean_env_wait_ms": 0.13953862441334378, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.005035301266926905, "sampler_results/connector_metrics/StateBufferConnector_ms": 0.0031939133686535903, "sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.20549338199551484, "info/learner/__all__/num_agent_steps_trained": 6144.0, "info/learner/__all__/num_env_steps_trained": 10000.0, "info/learner/__all__/total_loss": 3.0858777713775636, "info/learner/agent_0/total_loss": 3.0858777713775636, "info/learner/agent_0/policy_loss": -0.012776305861771108, "info/learner/agent_0/vf_loss": 4.406327133178711, "info/learner/agent_0/vf_loss_unclipped": 7.488041973114013, "info/learner/agent_0/vf_explained_var": 0.14001781463623048, "info/learner/agent_0/entropy": 1.5309498596191407, "info/learner/agent_0/mean_kl_loss": 0.014504875876009465, "info/learner/agent_0/default_optimizer_lr": 0.0005, "info/learner/agent_0/curr_lr": 0.0005, "info/learner/agent_0/curr_entropy_coeff": 0.01, "info/learner/agent_0/curr_kl_coeff": 0.0, "info/learner/agent_1/total_loss": 1.010226378440857, "info/learner/agent_1/policy_loss": -0.015089969877153634, "info/learner/agent_1/vf_loss": 4.158895635604859, "info/learner/agent_1/vf_loss_unclipped": 7.09940975189209, "info/learner/agent_1/vf_explained_var": 0.11917063474655151, "info/learner/agent_1/entropy": 1.4407552242279054, "info/learner/agent_1/mean_kl_loss": 0.013774582222104072, "info/learner/agent_1/default_optimizer_lr": 0.0005, "info/learner/agent_1/curr_lr": 0.0005, "info/learner/agent_1/curr_entropy_coeff": 0.01, "info/learner/agent_1/curr_kl_coeff": 0.0, "info/learner/agent_2/total_loss": 1.002155420780182, "info/learner/agent_2/policy_loss": -0.015266144052147865, "info/learner/agent_2/vf_loss": 4.127935485839844, "info/learner/agent_2/vf_loss_unclipped": 7.014230556488037, "info/learner/agent_2/vf_explained_var": 0.08173328638076782, "info/learner/agent_2/entropy": 1.4562305307388306, "info/learner/agent_2/mean_kl_loss": 0.010839902460575104, "info/learner/agent_2/default_optimizer_lr": 0.0005, "info/learner/agent_2/curr_lr": 0.0005, "info/learner/agent_2/curr_entropy_coeff": 0.01, "info/learner/agent_2/curr_kl_coeff": 0.0, "_timestamp": 1696522721.225711, "_runtime": 2000.2906260490417, "_step": 173, "evaluation/episode_reward_max": -4.0, "evaluation/episode_reward_min": -33.0, "evaluation/episode_reward_mean": -27.26, "evaluation/episode_len_mean": 10.97, "evaluation/episodes_this_iter": 100, "evaluation/num_faulty_episodes": 0, "evaluation/num_agent_steps_sampled_this_iter": 3291, "evaluation/num_env_steps_sampled_this_iter": 1097, "evaluation/timesteps_this_iter": 1097, "evaluation/num_healthy_workers": 0, "evaluation/num_in_flight_async_reqs": 0, "evaluation/num_remote_worker_restarts": 0, "evaluation/sampler_results/episode_reward_max": -4.0, "evaluation/sampler_results/episode_reward_min": -33.0, "evaluation/sampler_results/episode_reward_mean": -27.26, "evaluation/sampler_results/episode_len_mean": 10.97, "evaluation/sampler_results/episodes_this_iter": 100, "evaluation/sampler_results/num_faulty_episodes": 0, "evaluation/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "50975f71c711647d4495d82ee0156ae5ffb067153d0ce45a0ce262de721531e4", "size": 52427, "path": "media/videos/evaluation/episode_media/env_0_video_169_50975f71c711647d4495.mp4"}, {"_type": "video-file", "sha256": "de10642c41b46d640f3a64714f7a5fcda2f57008ac02a2c7f434ace1b37a5b4a", "size": 53903, "path": "media/videos/evaluation/episode_media/env_0_video_169_de10642c41b46d640f3a.mp4"}, {"_type": "video-file", "sha256": "85069f50be658ceb68a91a6414d0b1fcb2791577333eea0e762599065aa925b5", "size": 52128, "path": "media/videos/evaluation/episode_media/env_0_video_169_85069f50be658ceb68a9.mp4"}, {"_type": "video-file", "sha256": "d6fd19cc24d7c2aa8401821b21120234b802ff06c066efcab75954e5296e296e", "size": 56841, "path": "media/videos/evaluation/episode_media/env_0_video_169_d6fd19cc24d7c2aa8401.mp4"}, {"_type": "video-file", "sha256": "0521d5c86a5a69ee12fa1b62ffb65a0dd457330f1bdee8e373224d3121b1c904", "size": 51842, "path": "media/videos/evaluation/episode_media/env_0_video_169_0521d5c86a5a69ee12fa.mp4"}, {"_type": "video-file", "sha256": "8770eebf914e62d6e884cff7abb4fae49e67eec6d967497ca8e3cd8cd040a02c", "size": 52587, "path": "media/videos/evaluation/episode_media/env_0_video_169_8770eebf914e62d6e884.mp4"}], "captions": false}, "evaluation/policy_reward_min/agent_0": -11.0, "evaluation/policy_reward_min/agent_1": -11.0, "evaluation/policy_reward_min/agent_2": -11.0, "evaluation/policy_reward_max/agent_0": 1.0, "evaluation/policy_reward_max/agent_1": 1.0, "evaluation/policy_reward_max/agent_2": 1.0, "evaluation/policy_reward_mean/agent_0": -8.96, "evaluation/policy_reward_mean/agent_1": -8.97, "evaluation/policy_reward_mean/agent_2": -9.33, "evaluation/sampler_perf/mean_raw_obs_processing_ms": 2.4089301960580305, "evaluation/sampler_perf/mean_inference_ms": 3.7792308730567044, "evaluation/sampler_perf/mean_action_processing_ms": 0.22696734434806257, "evaluation/sampler_perf/mean_env_wait_ms": 0.10784627927229706, "evaluation/sampler_perf/mean_env_render_ms": 0.0, "evaluation/connector_metrics/ObsPreprocessorConnector_ms": 0.0037136077880859375, "evaluation/connector_metrics/StateBufferConnector_ms": 0.002505143483479818, "evaluation/connector_metrics/ViewRequirementAgentConnector_ms": 0.1687004566192627, "evaluation/sampler_results/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "50975f71c711647d4495d82ee0156ae5ffb067153d0ce45a0ce262de721531e4", "size": 52427, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_169_50975f71c711647d4495.mp4"}, {"_type": "video-file", "sha256": "de10642c41b46d640f3a64714f7a5fcda2f57008ac02a2c7f434ace1b37a5b4a", "size": 53903, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_169_de10642c41b46d640f3a.mp4"}, {"_type": "video-file", "sha256": "85069f50be658ceb68a91a6414d0b1fcb2791577333eea0e762599065aa925b5", "size": 52128, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_169_85069f50be658ceb68a9.mp4"}, {"_type": "video-file", "sha256": "d6fd19cc24d7c2aa8401821b21120234b802ff06c066efcab75954e5296e296e", "size": 56841, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_169_d6fd19cc24d7c2aa8401.mp4"}, {"_type": "video-file", "sha256": "0521d5c86a5a69ee12fa1b62ffb65a0dd457330f1bdee8e373224d3121b1c904", "size": 51842, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_169_0521d5c86a5a69ee12fa.mp4"}, {"_type": "video-file", "sha256": "8770eebf914e62d6e884cff7abb4fae49e67eec6d967497ca8e3cd8cd040a02c", "size": 52587, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_169_8770eebf914e62d6e884.mp4"}], "captions": false}, "evaluation/sampler_results/policy_reward_min/agent_0": -11.0, "evaluation/sampler_results/policy_reward_min/agent_1": -11.0, "evaluation/sampler_results/policy_reward_min/agent_2": -11.0, "evaluation/sampler_results/policy_reward_max/agent_0": 1.0, "evaluation/sampler_results/policy_reward_max/agent_1": 1.0, "evaluation/sampler_results/policy_reward_max/agent_2": 1.0, "evaluation/sampler_results/policy_reward_mean/agent_0": -8.96, "evaluation/sampler_results/policy_reward_mean/agent_1": -8.97, "evaluation/sampler_results/policy_reward_mean/agent_2": -9.33, "evaluation/sampler_results/sampler_perf/mean_raw_obs_processing_ms": 2.4089301960580305, "evaluation/sampler_results/sampler_perf/mean_inference_ms": 3.7792308730567044, "evaluation/sampler_results/sampler_perf/mean_action_processing_ms": 0.22696734434806257, "evaluation/sampler_results/sampler_perf/mean_env_wait_ms": 0.10784627927229706, "evaluation/sampler_results/sampler_perf/mean_env_render_ms": 0.0, "evaluation/sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.0037136077880859375, "evaluation/sampler_results/connector_metrics/StateBufferConnector_ms": 0.002505143483479818, "evaluation/sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.1687004566192627}
{"episode_reward_max": 3.0, "episode_reward_min": -15.0, "episode_reward_mean": -3.794103883949462, "episode_len_mean": 4.677585400093589, "episodes_this_iter": 2137, "num_faulty_episodes": 0, "num_healthy_workers": 8, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 4440000, "num_agent_steps_trained": 0, "num_env_steps_sampled": 1480000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 10000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 917.8003692117231, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 1480000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 4440000, "episodes_total": 303583, "training_iteration": 148, "timestamp": 1696508417, "time_this_iter_s": 10.934172630310059, "time_total_s": 1725.3442602157593, "time_since_restore": 1725.3442602157593, "iterations_since_restore": 148, "info/num_env_steps_sampled": 1480000, "info/num_env_steps_trained": 0, "info/num_agent_steps_sampled": 4440000, "info/num_agent_steps_trained": 0, "sampler_results/episode_reward_max": 3.0, "sampler_results/episode_reward_min": -15.0, "sampler_results/episode_reward_mean": -3.794103883949462, "sampler_results/episode_len_mean": 4.677585400093589, "sampler_results/episodes_this_iter": 2137, "sampler_results/num_faulty_episodes": 0, "policy_reward_min/agent_0": -6.0, "policy_reward_min/agent_1": -6.0, "policy_reward_min/agent_2": -6.0, "policy_reward_max/agent_0": 1.0, "policy_reward_max/agent_1": 1.0, "policy_reward_max/agent_2": 1.0, "policy_reward_mean/agent_0": -1.2732802994852597, "policy_reward_mean/agent_1": -1.2367805334581188, "policy_reward_mean/agent_2": -1.2840430510060834, "sampler_perf/mean_raw_obs_processing_ms": 1.842336033675228, "sampler_perf/mean_inference_ms": 4.5360120767858545, "sampler_perf/mean_action_processing_ms": 0.3020164350486047, "sampler_perf/mean_env_wait_ms": 0.1521975470184088, "sampler_perf/mean_env_render_ms": 0.0, "connector_metrics/ObsPreprocessorConnector_ms": 0.005656057764486819, "connector_metrics/StateBufferConnector_ms": 0.008037502727350864, "connector_metrics/ViewRequirementAgentConnector_ms": 0.23592177019013646, "timers/training_iteration_time_ms": 10832.168, "timers/sample_time_ms": 8981.933, "timers/synch_weights_time_ms": 11.81, "counters/num_env_steps_sampled": 1480000, "counters/num_env_steps_trained": 0, "counters/num_agent_steps_sampled": 4440000, "counters/num_agent_steps_trained": 0, "perf/cpu_util_percent": 24.660000000000004, "perf/ram_util_percent": 59.22666666666668, "perf/gpu_util_percent0": 0.10533333333333333, "perf/vram_util_percent0": 0.08058268229166667, "sampler_results/policy_reward_min/agent_0": -6.0, "sampler_results/policy_reward_min/agent_1": -6.0, "sampler_results/policy_reward_min/agent_2": -6.0, "sampler_results/policy_reward_max/agent_0": 1.0, "sampler_results/policy_reward_max/agent_1": 1.0, "sampler_results/policy_reward_max/agent_2": 1.0, "sampler_results/policy_reward_mean/agent_0": -1.2732802994852597, "sampler_results/policy_reward_mean/agent_1": -1.2367805334581188, "sampler_results/policy_reward_mean/agent_2": -1.2840430510060834, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.842336033675228, "sampler_results/sampler_perf/mean_inference_ms": 4.5360120767858545, "sampler_results/sampler_perf/mean_action_processing_ms": 0.3020164350486047, "sampler_results/sampler_perf/mean_env_wait_ms": 0.1521975470184088, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.005656057764486819, "sampler_results/connector_metrics/StateBufferConnector_ms": 0.008037502727350864, "sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.23592177019013646, "info/learner/__all__/num_agent_steps_trained": 6144.0, "info/learner/__all__/num_env_steps_trained": 10000.0, "info/learner/__all__/total_loss": 7.477847023010254, "info/learner/agent_0/total_loss": 7.477847023010254, "info/learner/agent_0/policy_loss": -0.0015373343415558338, "info/learner/agent_0/vf_loss": 9.985980339050293, "info/learner/agent_0/vf_loss_unclipped": 628.1537109375, "info/learner/agent_0/vf_explained_var": -0.03572286605834961, "info/learner/agent_0/entropy": 0.2450278115272522, "info/learner/agent_0/mean_kl_loss": 0.0022571288640392596, "info/learner/agent_0/default_optimizer_lr": 0.0005, "info/learner/agent_0/curr_lr": 0.0005, "info/learner/agent_0/curr_entropy_coeff": 0.01, "info/learner/agent_0/curr_kl_coeff": 0.0, "info/learner/agent_1/total_loss": 2.492249526977539, "info/learner/agent_1/policy_loss": -0.001614730190485716, "info/learner/agent_1/vf_loss": 9.985899696350097, "info/learner/agent_1/vf_loss_unclipped": 479.556396484375, "info/learner/agent_1/vf_explained_var": -0.9971912002563477, "info/learner/agent_1/entropy": 0.2610680490732193, "info/learner/agent_1/mean_kl_loss": 0.0028222209949854003, "info/learner/agent_1/default_optimizer_lr": 0.0005, "info/learner/agent_1/curr_lr": 0.0005, "info/learner/agent_1/curr_entropy_coeff": 0.01, "info/learner/agent_1/curr_kl_coeff": 0.0, "info/learner/agent_2/total_loss": 2.4930900955200195, "info/learner/agent_2/policy_loss": -0.0012640070728957653, "info/learner/agent_2/vf_loss": 9.986590499877929, "info/learner/agent_2/vf_loss_unclipped": 698.1431713867188, "info/learner/agent_2/vf_explained_var": -0.3031561517715454, "info/learner/agent_2/entropy": 0.22935582280158998, "info/learner/agent_2/mean_kl_loss": 0.002179191548916748, "info/learner/agent_2/default_optimizer_lr": 0.0005, "info/learner/agent_2/curr_lr": 0.0005, "info/learner/agent_2/curr_entropy_coeff": 0.01, "info/learner/agent_2/curr_kl_coeff": 0.0, "_timestamp": 1696508417.9592817, "_runtime": 1793.3440656661987, "_step": 147, "evaluation/episode_reward_max": 3.0, "evaluation/episode_reward_min": -11.0, "evaluation/episode_reward_mean": -3.51, "evaluation/episode_len_mean": 4.59, "evaluation/episodes_this_iter": 100, "evaluation/num_faulty_episodes": 0, "evaluation/num_agent_steps_sampled_this_iter": 1377, "evaluation/num_env_steps_sampled_this_iter": 459, "evaluation/timesteps_this_iter": 459, "evaluation/num_healthy_workers": 0, "evaluation/num_in_flight_async_reqs": 0, "evaluation/num_remote_worker_restarts": 0, "evaluation/sampler_results/episode_reward_max": 3.0, "evaluation/sampler_results/episode_reward_min": -11.0, "evaluation/sampler_results/episode_reward_mean": -3.51, "evaluation/sampler_results/episode_len_mean": 4.59, "evaluation/sampler_results/episodes_this_iter": 100, "evaluation/sampler_results/num_faulty_episodes": 0, "evaluation/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "13bd020c417b93c65b0d85b43ab5e09254805f279e12ec86c4eb2b910557d9ad", "size": 36343, "path": "media/videos/evaluation/episode_media/env_0_video_139_13bd020c417b93c65b0d.mp4"}, {"_type": "video-file", "sha256": "5d707d703b54d4f8edd70dee0a56423b08a3344fcd3ca4d67be1366984669a5d", "size": 38099, "path": "media/videos/evaluation/episode_media/env_0_video_139_5d707d703b54d4f8edd7.mp4"}, {"_type": "video-file", "sha256": "0fa8a3621083ecde3726cae6f5d380a5fc787017925ad3dc772e47440e8ec725", "size": 31516, "path": "media/videos/evaluation/episode_media/env_0_video_139_0fa8a3621083ecde3726.mp4"}, {"_type": "video-file", "sha256": "b1df4f36b65a8c0f93e6d814ace205182fa528f6e4bdd6664bdbf63e98ea51d3", "size": 33117, "path": "media/videos/evaluation/episode_media/env_0_video_139_b1df4f36b65a8c0f93e6.mp4"}, {"_type": "video-file", "sha256": "0ecc71b29a5f919c253424b61d021c1ee0e86b100262f102e32dbc5de1e7816a", "size": 30063, "path": "media/videos/evaluation/episode_media/env_0_video_139_0ecc71b29a5f919c2534.mp4"}, {"_type": "video-file", "sha256": "accb9b4e42fa3447ae69c0f8e967ee635d670a4e34ec2baad8bc5cec0d45be6f", "size": 31567, "path": "media/videos/evaluation/episode_media/env_0_video_139_accb9b4e42fa3447ae69.mp4"}], "captions": false}, "evaluation/policy_reward_min/agent_0": -5.0, "evaluation/policy_reward_min/agent_1": -6.0, "evaluation/policy_reward_min/agent_2": -6.0, "evaluation/policy_reward_max/agent_0": 1.0, "evaluation/policy_reward_max/agent_1": 1.0, "evaluation/policy_reward_max/agent_2": 1.0, "evaluation/policy_reward_mean/agent_0": -1.26, "evaluation/policy_reward_mean/agent_1": -1.03, "evaluation/policy_reward_mean/agent_2": -1.22, "evaluation/sampler_perf/mean_raw_obs_processing_ms": 2.9735197712777364, "evaluation/sampler_perf/mean_inference_ms": 3.8883909988908725, "evaluation/sampler_perf/mean_action_processing_ms": 0.2397984446156767, "evaluation/sampler_perf/mean_env_wait_ms": 0.12024656655457443, "evaluation/sampler_perf/mean_env_render_ms": 0.0, "evaluation/connector_metrics/ObsPreprocessorConnector_ms": 0.004081567128499349, "evaluation/connector_metrics/StateBufferConnector_ms": 0.006563663482666016, "evaluation/connector_metrics/ViewRequirementAgentConnector_ms": 0.18188110987345377, "evaluation/sampler_results/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "13bd020c417b93c65b0d85b43ab5e09254805f279e12ec86c4eb2b910557d9ad", "size": 36343, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_139_13bd020c417b93c65b0d.mp4"}, {"_type": "video-file", "sha256": "5d707d703b54d4f8edd70dee0a56423b08a3344fcd3ca4d67be1366984669a5d", "size": 38099, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_139_5d707d703b54d4f8edd7.mp4"}, {"_type": "video-file", "sha256": "0fa8a3621083ecde3726cae6f5d380a5fc787017925ad3dc772e47440e8ec725", "size": 31516, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_139_0fa8a3621083ecde3726.mp4"}, {"_type": "video-file", "sha256": "b1df4f36b65a8c0f93e6d814ace205182fa528f6e4bdd6664bdbf63e98ea51d3", "size": 33117, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_139_b1df4f36b65a8c0f93e6.mp4"}, {"_type": "video-file", "sha256": "0ecc71b29a5f919c253424b61d021c1ee0e86b100262f102e32dbc5de1e7816a", "size": 30063, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_139_0ecc71b29a5f919c2534.mp4"}, {"_type": "video-file", "sha256": "accb9b4e42fa3447ae69c0f8e967ee635d670a4e34ec2baad8bc5cec0d45be6f", "size": 31567, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_139_accb9b4e42fa3447ae69.mp4"}], "captions": false}, "evaluation/sampler_results/policy_reward_min/agent_0": -5.0, "evaluation/sampler_results/policy_reward_min/agent_1": -6.0, "evaluation/sampler_results/policy_reward_min/agent_2": -6.0, "evaluation/sampler_results/policy_reward_max/agent_0": 1.0, "evaluation/sampler_results/policy_reward_max/agent_1": 1.0, "evaluation/sampler_results/policy_reward_max/agent_2": 1.0, "evaluation/sampler_results/policy_reward_mean/agent_0": -1.26, "evaluation/sampler_results/policy_reward_mean/agent_1": -1.03, "evaluation/sampler_results/policy_reward_mean/agent_2": -1.22, "evaluation/sampler_results/sampler_perf/mean_raw_obs_processing_ms": 2.9735197712777364, "evaluation/sampler_results/sampler_perf/mean_inference_ms": 3.8883909988908725, "evaluation/sampler_results/sampler_perf/mean_action_processing_ms": 0.2397984446156767, "evaluation/sampler_results/sampler_perf/mean_env_wait_ms": 0.12024656655457443, "evaluation/sampler_results/sampler_perf/mean_env_render_ms": 0.0, "evaluation/sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.004081567128499349, "evaluation/sampler_results/connector_metrics/StateBufferConnector_ms": 0.006563663482666016, "evaluation/sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.18188110987345377}
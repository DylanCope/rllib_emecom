{"episode_reward_max": 2.8, "episode_reward_min": -3.3000000000000016, "episode_reward_mean": -2.153005464480875, "episode_len_mean": 10.94535519125683, "episodes_this_iter": 915, "num_faulty_episodes": 0, "num_healthy_workers": 8, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 0, "num_env_steps_sampled": 120000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 10000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 448.40711816622263, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 120000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 360000, "episodes_total": 10950, "training_iteration": 12, "timestamp": 1695854292, "time_this_iter_s": 22.327426433563232, "time_total_s": 307.6382179260254, "time_since_restore": 307.6382179260254, "iterations_since_restore": 12, "info/num_env_steps_sampled": 120000, "info/num_env_steps_trained": 0, "info/num_agent_steps_sampled": 360000, "info/num_agent_steps_trained": 0, "sampler_results/episode_reward_max": 2.8, "sampler_results/episode_reward_min": -3.3000000000000016, "sampler_results/episode_reward_mean": -2.153005464480875, "sampler_results/episode_len_mean": 10.94535519125683, "sampler_results/episodes_this_iter": 915, "sampler_results/num_faulty_episodes": 0, "policy_reward_min/agent_0": -1.0999999999999999, "policy_reward_min/agent_1": -1.0999999999999999, "policy_reward_min/agent_2": -1.0999999999999999, "policy_reward_max/agent_0": 1.0, "policy_reward_max/agent_1": 1.0, "policy_reward_max/agent_2": 1.0, "policy_reward_mean/agent_0": -0.6979234972677594, "policy_reward_mean/agent_1": -0.7306010928961747, "policy_reward_mean/agent_2": -0.7244808743169397, "sampler_perf/mean_raw_obs_processing_ms": 2.833214160353597, "sampler_perf/mean_inference_ms": 8.823570185312398, "sampler_perf/mean_action_processing_ms": 0.455099667927525, "sampler_perf/mean_env_wait_ms": 0.13793987823042556, "sampler_perf/mean_env_render_ms": 0.0, "connector_metrics/ObsPreprocessorConnector_ms": 0.005854752545799714, "connector_metrics/StateBufferConnector_ms": 0.0038405976008847762, "connector_metrics/ViewRequirementAgentConnector_ms": 0.31171898589976715, "timers/training_iteration_time_ms": 22441.361, "timers/sample_time_ms": 15625.508, "timers/synch_weights_time_ms": 15.265, "counters/num_env_steps_sampled": 120000, "counters/num_env_steps_trained": 0, "counters/num_agent_steps_sampled": 360000, "counters/num_agent_steps_trained": 0, "perf/cpu_util_percent": 24.066666666666666, "perf/ram_util_percent": 70.55666666666666, "perf/gpu_util_percent0": 0.03933333333333333, "perf/vram_util_percent0": 0.10056694878472223, "sampler_results/policy_reward_min/agent_0": -1.0999999999999999, "sampler_results/policy_reward_min/agent_1": -1.0999999999999999, "sampler_results/policy_reward_min/agent_2": -1.0999999999999999, "sampler_results/policy_reward_max/agent_0": 1.0, "sampler_results/policy_reward_max/agent_1": 1.0, "sampler_results/policy_reward_max/agent_2": 1.0, "sampler_results/policy_reward_mean/agent_0": -0.6979234972677594, "sampler_results/policy_reward_mean/agent_1": -0.7306010928961747, "sampler_results/policy_reward_mean/agent_2": -0.7244808743169397, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 2.833214160353597, "sampler_results/sampler_perf/mean_inference_ms": 8.823570185312398, "sampler_results/sampler_perf/mean_action_processing_ms": 0.455099667927525, "sampler_results/sampler_perf/mean_env_wait_ms": 0.13793987823042556, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.005854752545799714, "sampler_results/connector_metrics/StateBufferConnector_ms": 0.0038405976008847762, "sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.31171898589976715, "info/learner/__all__/num_agent_steps_trained": 66781.5, "info/learner/__all__/num_env_steps_trained": 10000.0, "info/learner/__all__/total_loss": 0.19347265362739563, "info/learner/agent_0/total_loss": 0.19347265362739563, "info/learner/agent_0/policy_loss": -0.001185671950224787, "info/learner/agent_0/vf_loss": 0.30565765127539635, "info/learner/agent_0/vf_loss_unclipped": 0.5169052816927433, "info/learner/agent_0/vf_explained_var": 0.030864320695400238, "info/learner/agent_0/entropy": 1.268656849861145, "info/learner/agent_0/mean_kl_loss": 0.0051784501811198425, "info/learner/agent_0/default_optimizer_lr": 0.0005, "info/learner/agent_0/curr_lr": 0.0005, "info/learner/agent_0/curr_entropy_coeff": 0.01, "info/learner/agent_0/curr_kl_coeff": 0.0, "info/learner/agent_1/total_loss": 0.06579393288120627, "info/learner/agent_1/policy_loss": 0.00023634952231077477, "info/learner/agent_1/vf_loss": 0.31309646740555763, "info/learner/agent_1/vf_loss_unclipped": 0.5070493929088116, "info/learner/agent_1/vf_explained_var": 0.031516946852207184, "info/learner/agent_1/entropy": 1.2716535180807114, "info/learner/agent_1/mean_kl_loss": 0.005199076080316445, "info/learner/agent_1/default_optimizer_lr": 0.0005, "info/learner/agent_1/curr_lr": 0.0005, "info/learner/agent_1/curr_entropy_coeff": 0.01, "info/learner/agent_1/curr_kl_coeff": 0.0, "info/learner/agent_2/total_loss": 0.06513654440641403, "info/learner/agent_2/policy_loss": -0.0003104838833678514, "info/learner/agent_2/vf_loss": 0.3127169646322727, "info/learner/agent_2/vf_loss_unclipped": 0.5138193890452385, "info/learner/agent_2/vf_explained_var": 0.03247586637735367, "info/learner/agent_2/entropy": 1.2732212543487549, "info/learner/agent_2/mean_kl_loss": 0.005600038952252362, "info/learner/agent_2/default_optimizer_lr": 0.0005, "info/learner/agent_2/curr_lr": 0.0005, "info/learner/agent_2/curr_entropy_coeff": 0.01, "info/learner/agent_2/curr_kl_coeff": 0.0, "_timestamp": 1695854292.3595216, "_runtime": 298.6439645290375, "_step": 11, "evaluation/episode_reward_max": 1.9, "evaluation/episode_reward_min": -3.3000000000000016, "evaluation/episode_reward_mean": -2.1870000000000003, "evaluation/episode_len_mean": 10.95, "evaluation/episodes_this_iter": 100, "evaluation/num_faulty_episodes": 0, "evaluation/num_agent_steps_sampled_this_iter": 3285, "evaluation/num_env_steps_sampled_this_iter": 1095, "evaluation/timesteps_this_iter": 1095, "evaluation/num_healthy_workers": 0, "evaluation/num_in_flight_async_reqs": 0, "evaluation/num_remote_worker_restarts": 0, "evaluation/sampler_results/episode_reward_max": 1.9, "evaluation/sampler_results/episode_reward_min": -3.3000000000000016, "evaluation/sampler_results/episode_reward_mean": -2.1870000000000003, "evaluation/sampler_results/episode_len_mean": 10.95, "evaluation/sampler_results/episodes_this_iter": 100, "evaluation/sampler_results/num_faulty_episodes": 0, "evaluation/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "dce18071df505a5ff36bbeadf6d41ca75ad6ffa042ffa5eeb29f02b931e38c9a", "size": 51447, "path": "media/videos/evaluation/episode_media/env_0_video_9_dce18071df505a5ff36b.mp4"}, {"_type": "video-file", "sha256": "5449c7c3ef4c8f3e94d855470e89562493931dd2a710b454cc4d19b230e0c40e", "size": 52729, "path": "media/videos/evaluation/episode_media/env_0_video_9_5449c7c3ef4c8f3e94d8.mp4"}, {"_type": "video-file", "sha256": "5dafad767a25280bb6c8c5f873602aaa2ec83dc865020142b63cdc35620359fc", "size": 48055, "path": "media/videos/evaluation/episode_media/env_0_video_9_5dafad767a25280bb6c8.mp4"}, {"_type": "video-file", "sha256": "4ec8777f2ec97be7a56cad0cc319622eb5ccd44466e964c0ac9df288fe2cb4ee", "size": 54020, "path": "media/videos/evaluation/episode_media/env_0_video_9_4ec8777f2ec97be7a56c.mp4"}, {"_type": "video-file", "sha256": "facb3d30b010777c516290c64529275759701e28ef222577488c95542758669d", "size": 49961, "path": "media/videos/evaluation/episode_media/env_0_video_9_facb3d30b010777c5162.mp4"}, {"_type": "video-file", "sha256": "b03455e861ac13031d4549659b5b8219494e4d86e7eea59c079fa1c5af81e0b6", "size": 48800, "path": "media/videos/evaluation/episode_media/env_0_video_9_b03455e861ac13031d45.mp4"}], "captions": false}, "evaluation/policy_reward_min/agent_0": -1.0999999999999999, "evaluation/policy_reward_min/agent_1": -1.0999999999999999, "evaluation/policy_reward_min/agent_2": -1.0999999999999999, "evaluation/policy_reward_max/agent_0": 1.0, "evaluation/policy_reward_max/agent_1": 1.0, "evaluation/policy_reward_max/agent_2": 1.0, "evaluation/policy_reward_mean/agent_0": -0.7039999999999997, "evaluation/policy_reward_mean/agent_1": -0.8219999999999997, "evaluation/policy_reward_mean/agent_2": -0.6609999999999998, "evaluation/sampler_perf/mean_raw_obs_processing_ms": 11.832494587793837, "evaluation/sampler_perf/mean_inference_ms": 7.425944735534002, "evaluation/sampler_perf/mean_action_processing_ms": 0.41633800868570375, "evaluation/sampler_perf/mean_env_wait_ms": 0.12726222511625634, "evaluation/sampler_perf/mean_env_render_ms": 0.0, "evaluation/connector_metrics/ObsPreprocessorConnector_ms": 0.004956642786661784, "evaluation/connector_metrics/StateBufferConnector_ms": 0.0033729076385498047, "evaluation/connector_metrics/ViewRequirementAgentConnector_ms": 0.26069410641988117, "evaluation/sampler_results/episode_media/env_0_video": {"_type": "videos", "count": 6, "videos": [{"_type": "video-file", "sha256": "dce18071df505a5ff36bbeadf6d41ca75ad6ffa042ffa5eeb29f02b931e38c9a", "size": 51447, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_9_dce18071df505a5ff36b.mp4"}, {"_type": "video-file", "sha256": "5449c7c3ef4c8f3e94d855470e89562493931dd2a710b454cc4d19b230e0c40e", "size": 52729, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_9_5449c7c3ef4c8f3e94d8.mp4"}, {"_type": "video-file", "sha256": "5dafad767a25280bb6c8c5f873602aaa2ec83dc865020142b63cdc35620359fc", "size": 48055, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_9_5dafad767a25280bb6c8.mp4"}, {"_type": "video-file", "sha256": "4ec8777f2ec97be7a56cad0cc319622eb5ccd44466e964c0ac9df288fe2cb4ee", "size": 54020, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_9_4ec8777f2ec97be7a56c.mp4"}, {"_type": "video-file", "sha256": "facb3d30b010777c516290c64529275759701e28ef222577488c95542758669d", "size": 49961, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_9_facb3d30b010777c5162.mp4"}, {"_type": "video-file", "sha256": "b03455e861ac13031d4549659b5b8219494e4d86e7eea59c079fa1c5af81e0b6", "size": 48800, "path": "media/videos/evaluation/sampler_results/episode_media/env_0_video_9_b03455e861ac13031d45.mp4"}], "captions": false}, "evaluation/sampler_results/policy_reward_min/agent_0": -1.0999999999999999, "evaluation/sampler_results/policy_reward_min/agent_1": -1.0999999999999999, "evaluation/sampler_results/policy_reward_min/agent_2": -1.0999999999999999, "evaluation/sampler_results/policy_reward_max/agent_0": 1.0, "evaluation/sampler_results/policy_reward_max/agent_1": 1.0, "evaluation/sampler_results/policy_reward_max/agent_2": 1.0, "evaluation/sampler_results/policy_reward_mean/agent_0": -0.7039999999999997, "evaluation/sampler_results/policy_reward_mean/agent_1": -0.8219999999999997, "evaluation/sampler_results/policy_reward_mean/agent_2": -0.6609999999999998, "evaluation/sampler_results/sampler_perf/mean_raw_obs_processing_ms": 11.832494587793837, "evaluation/sampler_results/sampler_perf/mean_inference_ms": 7.425944735534002, "evaluation/sampler_results/sampler_perf/mean_action_processing_ms": 0.41633800868570375, "evaluation/sampler_results/sampler_perf/mean_env_wait_ms": 0.12726222511625634, "evaluation/sampler_results/sampler_perf/mean_env_render_ms": 0.0, "evaluation/sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.004956642786661784, "evaluation/sampler_results/connector_metrics/StateBufferConnector_ms": 0.0033729076385498047, "evaluation/sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.26069410641988117}
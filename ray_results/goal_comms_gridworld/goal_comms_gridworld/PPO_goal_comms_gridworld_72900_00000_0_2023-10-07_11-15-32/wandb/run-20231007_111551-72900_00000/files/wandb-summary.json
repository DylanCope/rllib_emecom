{"episode_reward_max": -2.0, "episode_reward_min": -33.0, "episode_reward_mean": -28.322015334063526, "episode_len_mean": 10.97261774370208, "episodes_this_iter": 913, "num_faulty_episodes": 0, "num_healthy_workers": 8, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 90000, "num_agent_steps_trained": 0, "num_env_steps_sampled": 30000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 10000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 919.6908063108407, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 30000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 90000, "episodes_total": 2732, "training_iteration": 3, "timestamp": 1696673778, "time_this_iter_s": 10.890513181686401, "time_total_s": 32.36193799972534, "time_since_restore": 32.36193799972534, "iterations_since_restore": 3, "info/num_env_steps_sampled": 30000, "info/num_env_steps_trained": 0, "info/num_agent_steps_sampled": 90000, "info/num_agent_steps_trained": 0, "sampler_results/episode_reward_max": -2.0, "sampler_results/episode_reward_min": -33.0, "sampler_results/episode_reward_mean": -28.322015334063526, "sampler_results/episode_len_mean": 10.97261774370208, "sampler_results/episodes_this_iter": 913, "sampler_results/num_faulty_episodes": 0, "policy_reward_min/agent_0": -11.0, "policy_reward_min/agent_1": -11.0, "policy_reward_min/agent_2": -11.0, "policy_reward_max/agent_0": 1.0, "policy_reward_max/agent_1": 1.0, "policy_reward_max/agent_2": 1.0, "policy_reward_mean/agent_0": -9.428258488499452, "policy_reward_mean/agent_1": -9.397590361445783, "policy_reward_mean/agent_2": -9.496166484118291, "sampler_perf/mean_raw_obs_processing_ms": 1.6682393749083229, "sampler_perf/mean_inference_ms": 4.330035319868754, "sampler_perf/mean_action_processing_ms": 0.2950522077885403, "sampler_perf/mean_env_wait_ms": 0.14504993711945624, "sampler_perf/mean_env_render_ms": 0.0, "connector_metrics/ObsPreprocessorConnector_ms": 0.005502289949259039, "connector_metrics/StateBufferConnector_ms": 0.003543671311667123, "connector_metrics/ViewRequirementAgentConnector_ms": 0.22304906771974262, "timers/training_iteration_time_ms": 10769.279, "timers/sample_time_ms": 8345.193, "timers/synch_weights_time_ms": 12.008, "counters/num_env_steps_sampled": 30000, "counters/num_env_steps_trained": 0, "counters/num_agent_steps_sampled": 90000, "counters/num_agent_steps_trained": 0, "perf/cpu_util_percent": 25.686666666666667, "perf/ram_util_percent": 56.606666666666676, "perf/gpu_util_percent0": 0.04133333333333333, "perf/vram_util_percent0": 0.05288628472222222, "sampler_results/policy_reward_min/agent_0": -11.0, "sampler_results/policy_reward_min/agent_1": -11.0, "sampler_results/policy_reward_min/agent_2": -11.0, "sampler_results/policy_reward_max/agent_0": 1.0, "sampler_results/policy_reward_max/agent_1": 1.0, "sampler_results/policy_reward_max/agent_2": 1.0, "sampler_results/policy_reward_mean/agent_0": -9.428258488499452, "sampler_results/policy_reward_mean/agent_1": -9.397590361445783, "sampler_results/policy_reward_mean/agent_2": -9.496166484118291, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.6682393749083229, "sampler_results/sampler_perf/mean_inference_ms": 4.330035319868754, "sampler_results/sampler_perf/mean_action_processing_ms": 0.2950522077885403, "sampler_results/sampler_perf/mean_env_wait_ms": 0.14504993711945624, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "sampler_results/connector_metrics/ObsPreprocessorConnector_ms": 0.005502289949259039, "sampler_results/connector_metrics/StateBufferConnector_ms": 0.003543671311667123, "sampler_results/connector_metrics/ViewRequirementAgentConnector_ms": 0.22304906771974262, "info/learner/__all__/num_agent_steps_trained": 6144.0, "info/learner/__all__/num_env_steps_trained": 10000.0, "info/learner/__all__/total_loss": 3.954336471557617, "info/learner/agent_0/total_loss": 3.954336471557617, "info/learner/agent_0/policy_loss": -0.007907536388374865, "info/learner/agent_0/vf_loss": 5.400678367614746, "info/learner/agent_0/vf_loss_unclipped": 10.692707843780518, "info/learner/agent_0/vf_explained_var": 0.0059131884574890135, "info/learner/agent_0/entropy": 1.5807567739486694, "info/learner/agent_0/mean_kl_loss": 0.009050999851897359, "info/learner/agent_0/default_optimizer_lr": 0.0005, "info/learner/agent_0/curr_lr": 0.0005, "info/learner/agent_0/curr_entropy_coeff": 0.01, "info/learner/agent_0/curr_kl_coeff": 0.0, "info/learner/agent_1/total_loss": 1.3441978883743286, "info/learner/agent_1/policy_loss": -0.011289501953870058, "info/learner/agent_1/vf_loss": 5.485245838165283, "info/learner/agent_1/vf_loss_unclipped": 10.937663421630859, "info/learner/agent_1/vf_explained_var": 0.009424893856048585, "info/learner/agent_1/entropy": 1.582410092353821, "info/learner/agent_1/mean_kl_loss": 0.009268434699624777, "info/learner/agent_1/default_optimizer_lr": 0.0005, "info/learner/agent_1/curr_lr": 0.0005, "info/learner/agent_1/curr_entropy_coeff": 0.01, "info/learner/agent_1/curr_kl_coeff": 0.0, "info/learner/agent_2/total_loss": 1.283684072494507, "info/learner/agent_2/policy_loss": -0.007267834870144724, "info/learner/agent_2/vf_loss": 5.226990566253662, "info/learner/agent_2/vf_loss_unclipped": 9.67374382019043, "info/learner/agent_2/vf_explained_var": 0.012495863437652587, "info/learner/agent_2/entropy": 1.5795734930038452, "info/learner/agent_2/mean_kl_loss": 0.009338520299643278, "info/learner/agent_2/default_optimizer_lr": 0.0005, "info/learner/agent_2/curr_lr": 0.0005, "info/learner/agent_2/curr_entropy_coeff": 0.01, "info/learner/agent_2/curr_kl_coeff": 0.0, "_timestamp": 1696673778.9556046, "_runtime": 27.85139751434326, "_step": 2}
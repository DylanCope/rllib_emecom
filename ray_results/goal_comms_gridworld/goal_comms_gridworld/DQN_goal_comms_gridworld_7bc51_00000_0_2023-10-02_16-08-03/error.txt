Failure # 1 (occurred at 2023-10-02_16-08-20)
The actor died because of an error raised in its creation task, [36mray::DQN.__init__()[39m (pid=20780, ip=172.26.22.84, actor_id=254e075eca09b05abd02a80901000000, repr=DQN)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/worker_set.py", line 227, in _setup
    self.add_workers(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/worker_set.py", line 593, in add_workers
    raise result.get()
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/utils/actor_manager.py", line 481, in __fetch_result
    result = ray.get(r)
ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, [36mray::RolloutWorker.__init__()[39m (pid=21060, ip=172.26.22.84, actor_id=5a68887b9643a157f105925301000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f1739924a60>)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 525, in __init__
    self._update_policy_map(policy_dict=self.policy_dict)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 1727, in _update_policy_map
    self._build_policy_map(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 1838, in _build_policy_map
    new_policy = create_policy_for_framework(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/utils/policy.py", line 142, in create_policy_for_framework
    return policy_class(observation_space, action_space, merged_config)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/policy/policy_template.py", line 328, in __init__
    self._initialize_loss_from_dummy_batch(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/policy/policy.py", line 1418, in _initialize_loss_from_dummy_batch
    actions, state_outs, extra_outs = self.compute_actions_from_input_dict(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/policy/torch_policy.py", line 326, in compute_actions_from_input_dict
    return self._compute_action_helper(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/utils/threading.py", line 24, in wrapper
    return func(self, *a, **k)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/policy/torch_policy.py", line 1033, in _compute_action_helper
    action_dist = dist_class(dist_inputs, self.model)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/models/torch/torch_action_dist.py", line 118, in __init__
    super().__init__(inputs, model, temperature)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/models/torch/torch_action_dist.py", line 88, in __init__
    assert temperature > 0.0, "Categorical `temperature` must be > 0.0!"
AssertionError: Categorical `temperature` must be > 0.0!

During handling of the above exception, another exception occurred:

[36mray::DQN.__init__()[39m (pid=20780, ip=172.26.22.84, actor_id=254e075eca09b05abd02a80901000000, repr=DQN)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/utils/deprecation.py", line 106, in patched_init
    return obj_init(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/algorithm.py", line 517, in __init__
    super().__init__(
  File "/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py", line 185, in __init__
    self.setup(copy.deepcopy(self.config))
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/algorithms/algorithm.py", line 639, in setup
    self.workers = WorkerSet(
  File "/usr/local/lib/python3.10/dist-packages/ray/rllib/evaluation/worker_set.py", line 179, in __init__
    raise e.args[0].args[2]
AssertionError: Categorical `temperature` must be > 0.0!

2023-09-29 21:25:24,217 INFO    MainThread:2487 [wandb_setup.py:_flush():76] Current SDK version is 0.15.10
2023-09-29 21:25:24,218 INFO    MainThread:2487 [wandb_setup.py:_flush():76] Configure stats pid to 2487
2023-09-29 21:25:24,218 INFO    MainThread:2487 [wandb_setup.py:_flush():76] Loading settings from /root/.config/wandb/settings
2023-09-29 21:25:24,218 INFO    MainThread:2487 [wandb_setup.py:_flush():76] Loading settings from /root/ray_results/goal_comms_gridworld/PPO_goal_comms_gridworld_2abb8_00000_0_2023-09-29_21-24-18/wandb/settings
2023-09-29 21:25:24,218 INFO    MainThread:2487 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'api_key': '***REDACTED***', 'start_method': 'thread'}
2023-09-29 21:25:24,218 INFO    MainThread:2487 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-09-29 21:25:24,218 WARNING MainThread:2487 [wandb_setup.py:_flush():76] Could not save program above cwd: /usr/local/lib/python3.10/dist-packages/ray/_private/workers/default_worker.py
2023-09-29 21:25:24,218 INFO    MainThread:2487 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': None, 'program': '/usr/local/lib/python3.10/dist-packages/ray/_private/workers/default_worker.py'}
2023-09-29 21:25:24,218 INFO    MainThread:2487 [wandb_init.py:_log_setup():524] Logging user logs to /root/ray_results/goal_comms_gridworld/PPO_goal_comms_gridworld_2abb8_00000_0_2023-09-29_21-24-18/wandb/run-20230929_212524-2abb8_00000/logs/debug.log
2023-09-29 21:25:24,218 INFO    MainThread:2487 [wandb_init.py:_log_setup():525] Logging internal logs to /root/ray_results/goal_comms_gridworld/PPO_goal_comms_gridworld_2abb8_00000_0_2023-09-29_21-24-18/wandb/run-20230929_212524-2abb8_00000/logs/debug-internal.log
2023-09-29 21:25:24,218 INFO    MainThread:2487 [wandb_init.py:init():564] calling init triggers
2023-09-29 21:25:24,218 INFO    MainThread:2487 [wandb_init.py:init():571] wandb.init called with sweep_config: {}
config: {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f89e65791b0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': -1, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': (None, None, None, None), 'agent_0': (None, None, None, None)}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8}
2023-09-29 21:25:24,218 INFO    MainThread:2487 [wandb_init.py:init():614] starting backend
2023-09-29 21:25:24,218 INFO    MainThread:2487 [wandb_init.py:init():618] setting up manager
2023-09-29 21:25:24,221 INFO    MainThread:2487 [wandb_init.py:init():624] backend started and connected
2023-09-29 21:25:24,224 INFO    MainThread:2487 [wandb_init.py:init():715] updated telemetry
2023-09-29 21:25:24,225 INFO    MainThread:2487 [wandb_init.py:init():748] communicating run to backend with 90.0 second timeout
2023-09-29 21:25:24,777 INFO    MainThread:2487 [wandb_run.py:_on_init():2220] communicating current version
2023-09-29 21:25:24,898 INFO    MainThread:2487 [wandb_run.py:_on_init():2229] got version response upgrade_message: "wandb version 0.15.11 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-09-29 21:25:24,898 INFO    MainThread:2487 [wandb_init.py:init():799] starting run threads in backend
2023-09-29 21:25:25,016 INFO    MainThread:2487 [wandb_run.py:_console_start():2199] atexit reg
2023-09-29 21:25:25,016 INFO    MainThread:2487 [wandb_run.py:_redirect():2054] redirect: wrap_raw
2023-09-29 21:25:25,016 INFO    MainThread:2487 [wandb_run.py:_redirect():2119] Wrapping output streams.
2023-09-29 21:25:25,016 INFO    MainThread:2487 [wandb_run.py:_redirect():2144] Redirects installed.
2023-09-29 21:25:25,017 INFO    MainThread:2487 [wandb_init.py:init():840] run started, returning control to user process
2023-09-29 21:25:25,017 INFO    MainThread:2487 [wandb_config.py:__setitem__():151] config set trial_log_path = /root/ray_results/goal_comms_gridworld/PPO_goal_comms_gridworld_2abb8_00000_0_2023-09-29_21-24-18 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x7fa6d0a71b10>>
2023-09-29 21:25:25,018 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb trial_log_path /root/ray_results/goal_comms_gridworld/PPO_goal_comms_gridworld_2abb8_00000_0_2023-09-29_21-24-18 None
2023-09-29 21:25:41,686 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945badc60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-25-38', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:26:01,664 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945bae680>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-26-01', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:26:21,670 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945badea0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-26-21', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:26:41,423 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945cfd7e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-26-41', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:27:01,558 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945cfe440>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-27-01', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:27:21,434 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945cff0a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-27-21', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:27:41,364 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945cffd90>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-27-41', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:28:01,380 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c18d30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-28-01', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:28:20,980 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945cfeb00>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-28-20', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:28:45,297 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945cfd240>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-28-45', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:29:05,176 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945cfff40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-29-05', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:29:24,694 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945bade10>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-29-24', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:29:46,510 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945bae0e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-29-46', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:30:07,385 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c18d30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-30-06', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:30:27,994 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c197e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-30-27', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:30:47,620 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1a320>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-30-47', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:31:06,847 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1aef0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-31-06', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:31:26,565 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945bad990>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-31-26', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:31:46,020 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1a050>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-31-46', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:32:10,030 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c19480>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-32-10', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:32:29,715 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1b490>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-32-29', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:32:49,673 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1b250>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-32-49', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:33:09,562 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c19ab0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-33-09', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:33:29,192 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1ab90>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-33-29', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:33:49,283 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1bb50>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-33-49', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:34:09,391 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1bbe0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-34-09', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:34:29,422 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945cfeb90>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-34-29', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:34:49,896 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1b370>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-34-49', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:35:17,481 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1beb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-35-17', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:35:41,792 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f89b6b88c10>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-35-41', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:36:01,483 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945bae680>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-36-01', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:36:21,149 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1ab90>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-36-21', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:36:40,724 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1a440>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-36-40', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:37:00,479 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2cd30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-37-00', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:37:20,117 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2d900>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-37-20', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:37:39,775 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1be20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-37-39', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:37:59,298 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945bade10>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-37-59', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:38:19,003 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2d480>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-38-18', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:38:38,717 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2dea0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-38-38', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:39:02,782 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2ecb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-39-02', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:39:22,453 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1ad40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-39-22', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:39:42,663 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1aef0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-39-42', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:40:02,773 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f89b6c82b00>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-40-02', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:40:22,486 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f89b6b09e10>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-40-22', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:40:42,085 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1aef0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-40-42', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:41:01,615 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2da20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-41-01', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:41:21,286 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2d480>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-41-21', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:41:41,231 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2fb50>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-41-41', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:42:01,083 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2eb00>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-42-01', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:42:25,479 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2e050>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-42-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:42:45,208 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c1a9e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-42-45', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:43:04,961 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2e7a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-43-04', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:43:24,759 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2dcf0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-43-24', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:43:44,674 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c19f30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-43-44', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:44:04,863 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c18b80>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-44-04', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:44:24,505 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2e170>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-44-24', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:44:46,092 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945cfda20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-44-44', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:45:06,512 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2ec20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-45-06', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:45:26,157 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2eef0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-45-26', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:45:50,220 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2f130>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-45-50', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:46:09,848 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf349d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-46-09', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:46:29,532 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2f010>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-46-29', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:46:49,317 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2fd90>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-46-49', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:47:09,479 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf34550>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-47-09', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:47:29,482 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf353f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-47-29', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:47:50,729 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf35f30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-47-50', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:48:11,019 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2da20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-48-11', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:48:31,215 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c19fc0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-48-31', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:48:51,548 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf35510>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-48-51', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:49:16,063 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf360e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-49-16', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:49:36,100 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945bada20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-49-36', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:49:57,143 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945bade10>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-49-56', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:50:22,782 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f89b6b09e10>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-50-17', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:50:42,752 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945b42cb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-50-42', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:51:02,753 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf35d80>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-51-02', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:51:22,876 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf35bd0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-51-22', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:51:43,088 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf35f30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-51-42', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:52:03,158 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf371c0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-52-03', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:52:23,422 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2da20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-52-23', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:52:48,449 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf37130>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-52-48', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:53:08,898 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf36560>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-53-08', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:53:29,068 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2d480>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-53-29', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:53:49,289 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf35510>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-53-49', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:54:09,907 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945c19f30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-54-09', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:54:29,938 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2cee0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-54-29', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:54:50,407 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f89b6b09e10>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-54-50', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:55:11,028 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf36710>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-55-11', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:55:32,494 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf37490>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-55-32', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:55:52,438 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf355a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-55-52', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:56:17,090 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0acd30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-56-17', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:56:37,590 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf37760>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-56-37', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:56:57,557 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945bade10>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-56-57', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:57:17,598 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0aca60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-57-17', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:57:37,329 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0adb40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-57-37', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:57:57,187 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf37d90>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-57-57', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:58:16,866 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0ad7e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-58-16', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:58:36,976 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0ac1f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-58-36', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:58:57,357 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0ae050>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-58-57', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:59:17,816 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0aeb90>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-59-17', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 21:59:42,726 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf37130>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_21-59-42', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:00:03,425 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf37760>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-00-03', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:00:27,603 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf36950>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-00-27', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:00:47,804 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945badab0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-00-47', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:01:07,648 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945baed40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-01-07', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:01:27,443 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf36950>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-01-27', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:01:47,439 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945badab0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-01-47', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:02:07,166 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945baed40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-02-07', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:02:27,297 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf36950>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-02-27', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:02:47,373 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945badab0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-02-47', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:03:12,191 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf37760>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-03-12', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:03:32,497 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945badab0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-03-32', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:03:52,452 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2e7a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-03-52', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:04:13,321 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf37400>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-04-13', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:04:34,966 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf371c0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-04-34', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:04:55,785 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2e7a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-04-55', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:05:17,556 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0ad360>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-05-17', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:05:45,999 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0af880>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-05-38', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:06:06,889 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2e7a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-06-06', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:06:27,591 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0ac940>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-06-27', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:06:53,304 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0af5b0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-06-53', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:07:14,544 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0ac940>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-07-14', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:07:35,694 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0add80>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-07-35', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:07:56,812 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf345e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-07-56', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:08:17,964 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf37400>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-08-17', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:08:39,372 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8945bada20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-08-39', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:09:00,536 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0af910>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-09-00', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:09:21,589 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0ac160>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-09-21', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:09:42,697 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca03a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-09-42', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:10:04,281 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2cee0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-10-04', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:10:36,097 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0afc70>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-10-30', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:10:58,028 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca1ea0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-10-57', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:11:19,085 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca1240>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-11-19', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:11:40,396 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0ac1f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-11-40', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:12:01,438 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca1bd0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-12-01', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:12:22,597 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca0790>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-12-22', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:12:43,568 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca0d30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-12-43', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:13:04,950 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca2e60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-13-04', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:13:25,760 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf35fc0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-13-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:13:46,552 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca1cf0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-13-46', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:14:12,775 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf34790>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-14-12', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:14:32,349 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf36710>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-14-32', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:14:52,053 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca1bd0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-14-52', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:15:11,670 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0ac940>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-15-11', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:15:32,624 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca30a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-15-32', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:15:53,161 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0aff40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-15-52', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:16:12,647 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0ad090>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-16-12', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:16:32,405 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3be0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-16-32', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:16:51,877 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca2170>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-16-51', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:17:11,449 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3c8b0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-17-11', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:17:35,640 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3d00>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-17-35', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:17:55,339 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0aca60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-17-55', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:18:14,790 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3cd30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-18-14', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:18:34,721 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca20e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-18-34', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:18:54,731 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0aca60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-18-54', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:19:14,453 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3c8b0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-19-14', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:19:34,319 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3dbd0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-19-34', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:19:53,807 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3e680>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-19-53', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:20:13,577 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca37f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-20-13', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:20:34,281 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3880>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-20-34', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:21:09,521 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0ac550>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-21-09', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:21:29,553 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3880>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-21-29', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:21:49,310 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca37f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-21-49', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:22:08,984 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca20e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-22-08', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:22:28,836 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3880>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-22-28', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:22:48,550 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca37f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-22-48', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:23:08,185 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca20e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-23-08', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:23:27,886 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3880>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-23-27', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:23:47,531 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca37f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-23-47', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:24:07,531 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf36710>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-24-07', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:24:31,691 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c0ac550>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-24-31', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:24:51,490 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf36710>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-24-51', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:25:11,118 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca2710>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-25-11', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:25:30,957 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3c70>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-25-30', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:25:50,860 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf36710>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-25-50', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:26:10,364 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca2c20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-26-10', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:26:29,776 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca1000>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-26-29', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:26:49,347 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf36710>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-26-49', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:27:08,922 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca2c20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-27-08', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:27:28,369 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca1000>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-27-28', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:27:52,610 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3c70>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-27-52', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:28:12,253 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3ac0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-28-12', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:28:31,806 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3dc60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-28-31', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:28:51,567 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3d630>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-28-51', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:29:11,344 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3ff40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-29-11', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:29:30,766 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c174e50>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-29-30', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:29:50,469 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3dc60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-29-50', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:30:10,207 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3f130>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-30-10', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:30:29,650 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf36710>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-30-29', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:30:54,796 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3d630>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-30-50', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:31:18,816 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca1000>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-31-18', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:31:38,866 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3d630>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-31-38', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:31:58,710 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3ce50>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-31-58', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:32:18,684 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca1000>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-32-18', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:32:38,140 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3c5e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-32-38', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:32:57,602 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3d240>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-32-57', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:33:17,323 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3feb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-33-17', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:33:36,830 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca36d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-33-36', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:33:56,510 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c175000>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-33-56', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:34:16,681 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3760>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-34-16', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:34:41,076 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3fc70>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-34-41', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:35:00,697 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3760>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-35-00', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:35:20,490 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c176440>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-35-20', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:35:41,085 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3ac0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-35-41', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:36:01,331 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3b50>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-36-01', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:36:23,115 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3760>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-36-23', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:36:42,827 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c176a70>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-36-42', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:37:02,421 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c177640>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-37-02', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:37:22,250 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c177f40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-37-22', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:37:41,960 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c176560>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-37-41', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:38:06,033 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c175120>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-38-06', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:38:25,601 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c1d4310>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-38-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:38:45,292 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c174c10>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-38-45', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:39:05,015 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c176680>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-39-04', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:39:24,394 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c1771c0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-39-24', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:39:43,849 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16cb80>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-39-43', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:40:03,545 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16d990>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-40-03', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:40:23,398 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c176560>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-40-23', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:40:43,244 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3d00>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-40-43', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:41:09,472 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c177250>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-41-09', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:41:33,596 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16c550>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-41-33', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:41:53,209 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16e050>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-41-53', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:42:13,019 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c176ef0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-42-13', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:42:32,806 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16c040>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-42-32', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:42:52,389 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16dbd0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-42-52', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:43:11,910 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16eef0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-43-11', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:43:31,768 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16fac0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-43-31', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:43:51,466 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bca3eb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-43-51', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:44:11,276 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c175fc0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-44-11', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:44:30,720 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c177880>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-44-30', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:44:54,944 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16f520>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-44-54', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:45:14,580 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c1771c0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-45-14', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:45:34,238 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16f9a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-45-34', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:45:54,506 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c177130>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-45-54', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:46:14,696 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c1777f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-46-14', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:46:34,416 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891be3feb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-46-34', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:46:54,409 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c177130>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-46-54', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:47:14,196 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16ef80>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-47-14', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:47:33,878 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837374820>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-47-33', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:47:53,780 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837375480>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-47-53', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:48:18,106 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16ca60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-48-18', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:48:37,859 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88373752d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-48-37', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:48:57,272 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837375750>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-48-57', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:49:16,833 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16c040>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-49-16', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:49:36,316 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88373757e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-49-36', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:49:55,966 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837375b40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-49-55', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:50:15,618 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88373767a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-50-15', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:50:35,451 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88373772e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-50-35', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:50:55,804 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16eb00>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-50-55', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:51:16,016 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c175ab0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-51-15', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:51:41,920 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88373770a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-51-41', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:52:01,818 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837374a60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-52-01', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:52:21,719 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88373770a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-52-21', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:52:41,507 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88373745e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-52-41', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:53:01,198 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837375120>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-53-01', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:53:20,796 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837377d90>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-53-20', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:53:40,556 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88373509d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-53-40', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:54:00,503 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88373755a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-54-00', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:54:20,456 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837375120>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-54-20', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:54:39,976 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88373752d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-54-39', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:55:04,025 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837350700>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-55-04', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:55:23,824 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837377e20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-55-23', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:55:43,410 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837350820>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-55-43', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:56:03,519 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837374a60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-56-03', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:56:25,385 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837375870>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-56-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:56:45,148 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16e950>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-56-45', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:57:04,656 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837352050>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-57-04', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:57:24,277 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16db40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-57-24', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:57:44,034 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837350f70>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-57-43', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:58:03,656 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16ce50>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-58-03', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:58:27,549 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837352b90>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-58-27', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:58:47,302 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837351f30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-58-47', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:59:06,949 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16ef80>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-59-06', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:59:26,887 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837352320>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-59-26', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 22:59:46,556 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837353010>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_22-59-46', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:00:06,268 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837353b50>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-00-06', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:00:25,697 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837352320>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-00-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:00:45,314 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88373505e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-00-45', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:01:05,552 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16e950>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-01-05', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:01:26,983 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88373505e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-01-26', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:01:51,458 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16ca60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-01-51', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:02:11,284 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88373505e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-02-11', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:02:31,050 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837351cf0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-02-31', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:02:50,806 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16ca60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-02-50', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:03:10,581 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0cd30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-03-10', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:03:30,194 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837352050>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-03-30', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:03:49,951 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16ef80>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-03-49', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:04:10,046 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16ca60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-04-09', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:04:29,397 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837352320>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-04-29', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:04:49,056 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837351cf0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-04-49', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:05:13,259 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0c5e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-05-13', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:05:33,053 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0dcf0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-05-33', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:05:52,744 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c175ab0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-05-52', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:06:12,948 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16c160>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-06-12', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:06:33,082 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837351000>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-06-33', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:06:52,760 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c175ab0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-06-52', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:07:12,324 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16c160>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-07-12', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:07:31,990 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837351000>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-07-31', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:07:51,626 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c175ab0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-07-51', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:08:11,210 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16c160>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-08-11', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:08:35,100 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837351000>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-08-35', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:08:54,947 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16c160>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-08-54', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:09:14,954 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0eef0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-09-14', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:09:34,448 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837351000>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-09-34', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:09:53,923 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16c160>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-09-53', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:10:13,673 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0e7a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-10-13', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:10:33,319 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0e170>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-10-33', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:10:53,071 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891c16c160>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-10-53', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:11:13,176 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837375900>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-11-13', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:11:40,063 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f640>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-11-33', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:12:04,197 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f1c0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-12-04', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:12:24,307 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0ee60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-12-24', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:12:44,117 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2cee0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-12-44', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:13:03,791 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0dfc0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-13-03', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:13:23,297 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f9a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-13-23', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:13:42,936 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88373536d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-13-42', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:14:02,763 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837351360>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-14-02', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:14:22,446 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f7f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-14-22', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:14:42,272 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f910>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-14-42', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:15:02,095 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba64af0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-15-02', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:15:26,150 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba655a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-15-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:15:45,707 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0e560>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-15-45', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:16:05,487 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba64040>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-16-05', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:16:25,660 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837377a30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-16-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:16:45,645 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837353eb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-16-45', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:17:05,229 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f7f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-17-05', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:17:24,809 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837377a30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-17-24', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:17:44,637 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837353eb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-17-44', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:18:04,441 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f7f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-18-04', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:18:24,304 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837377a30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-18-24', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:18:48,343 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba669e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-18-48', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:19:08,049 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f760>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-19-08', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:19:27,815 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba66cb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-19-27', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:19:47,656 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837353eb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-19-47', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:20:07,448 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba65240>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-20-07', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:20:27,059 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba67f40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-20-27', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:20:46,738 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba67d00>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-20-46', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:21:06,366 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba66b00>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-21-06', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:21:26,261 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837377a30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-21-26', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:21:46,817 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0e560>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-21-46', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:22:10,810 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f370>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-22-10', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:22:30,673 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0e560>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-22-30', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:22:50,517 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba67eb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-22-50', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:23:10,066 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b14b80>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-23-10', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:23:30,026 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba66830>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-23-30', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:23:50,110 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f0a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-23-49', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:24:10,078 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0fd90>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-24-10', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:24:29,931 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba67d00>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-24-29', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:24:49,550 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba656c0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-24-49', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:25:09,147 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b15120>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-25-09', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:25:33,204 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f1c0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-25-33', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:25:53,178 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b15990>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-25-53', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:26:12,906 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b164d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-26-12', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:26:33,047 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba65510>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-26-33', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:26:53,573 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b15510>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-26-53', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:27:12,991 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b165f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-27-12', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:27:32,597 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b168c0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-27-32', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:27:52,102 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b179a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-27-52', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:28:11,948 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b17520>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-28-11', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:28:31,652 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b15480>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-28-31', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:28:55,962 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2cee0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-28-55', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:29:15,752 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0fd00>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-29-15', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:29:35,867 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b17be0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-29-35', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:29:55,988 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b17880>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-29-55', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:30:15,647 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774d2d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-30-15', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:30:35,402 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774dea0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-30-35', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:30:55,408 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b17910>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-30-55', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:31:15,356 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f370>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-31-15', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:31:35,757 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba67f40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-31-35', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:31:58,138 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b16a70>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-31-56', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:32:22,902 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f370>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-32-22', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:32:42,849 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b168c0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-32-42', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:33:02,722 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891bf2cee0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-33-02', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:33:22,523 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b160e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-33-22', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:33:42,389 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b168c0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-33-42', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:34:02,764 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f370>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-34-02', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:34:22,543 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba65cf0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-34-22', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:34:42,427 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba676d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-34-42', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:35:02,400 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba65360>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-35-02', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:35:22,238 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774c940>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-35-22', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:35:46,498 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774d3f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-35-46', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:36:06,213 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b15990>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-36-06', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:36:25,563 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774eb00>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-36-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:36:45,899 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774f5b0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-36-45', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:37:06,094 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774dea0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-37-06', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:37:25,793 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774fd90>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-37-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:37:45,468 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774f5b0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-37-45', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:38:05,095 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774f1c0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-38-05', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:38:24,829 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774e8c0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-38-24', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:38:44,360 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774fd90>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-38-44', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:39:08,316 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774ed40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-39-08', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:39:28,222 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774f400>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-39-28', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:39:47,903 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774cee0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-39-47', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:40:07,592 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b15480>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-40-07', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:40:27,126 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b16f80>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-40-27', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:40:46,252 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774fd90>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-40-46', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:41:05,812 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a0790>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-41-05', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:41:25,691 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774fd00>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-41-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:41:45,585 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0f370>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-41-45', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:42:06,671 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774f5b0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-42-06', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:42:30,861 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774d5a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-42-30', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:42:50,517 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774e0e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-42-50', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:43:10,197 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0d2d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-43-10', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:43:30,029 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a1b40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-43-30', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:43:49,776 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba657e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-43-49', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:44:09,804 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b17be0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-44-09', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:44:29,526 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774fc70>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-44-29', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:44:48,999 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a17e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-44-48', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:45:08,692 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774da20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-45-08', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:45:28,328 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a1d80>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-45-28', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:45:52,428 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774e0e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-45-52', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:46:12,093 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837b167a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-46-12', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:46:31,782 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a2e60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-46-31', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:46:51,894 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba657e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-46-51', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:47:12,525 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a3520>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-47-12', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:47:32,009 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a2440>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-47-31', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:47:51,720 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a1fc0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-47-51', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:48:11,458 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a3910>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-48-11', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:48:31,694 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774e830>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-48-31', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:48:51,403 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a3a30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-48-51', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:49:15,421 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a01f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-49-15', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:49:35,435 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a2e60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-49-35', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:49:55,448 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f681f0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-49-55', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:50:14,996 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a3010>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-50-14', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:50:34,639 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a0790>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-50-34', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:50:54,304 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a3910>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-50-54', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:51:13,996 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a2e60>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-51-13', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:51:33,743 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a2200>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-51-33', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:51:53,647 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a2320>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-51-53', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:52:20,343 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a3a30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-52-20', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:52:44,448 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a35b0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-52-44', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:53:04,316 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a2200>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-53-04', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:53:23,953 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a0790>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-53-23', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:53:43,390 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774f520>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-53-43', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:54:03,375 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f891ba657e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-54-03', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:54:23,123 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a2c20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-54-23', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:54:42,814 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0d2d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-54-42', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:55:02,440 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f69480>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-55-02', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:55:22,043 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6a290>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-55-22', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:55:41,669 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f68f70>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-55-41', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:56:05,537 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6af80>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-56-05', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:56:25,134 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6b490>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-56-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:56:44,754 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6bac0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-56-44', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:57:04,921 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a1480>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-57-04', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:57:24,929 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a3010>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-57-24', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:57:44,799 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a30a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-57-44', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:58:04,641 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a1480>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-58-04', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:58:24,277 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a3010>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-58-24', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:58:44,006 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774e680>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-58-43', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:59:03,683 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a1480>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-59-03', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:59:27,870 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a30a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-59-27', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-29 23:59:47,582 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a1480>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-29_23-59-47', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:00:07,346 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774e680>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-00-07', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:00:26,960 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a30a0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-00-26', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:00:46,524 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a1480>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-00-46', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:01:06,003 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6beb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-01-05', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:01:25,538 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6ac20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-01-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:01:45,342 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6be20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-01-45', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:02:05,510 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774e680>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-02-05', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:02:25,763 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0d2d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-02-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:02:49,910 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6b520>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-02-49', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:03:09,573 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0d2d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-03-09', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:03:29,308 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f69f30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-03-29', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:03:48,958 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6ab00>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-03-48', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:04:08,905 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774db40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-04-08', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:04:28,470 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774f520>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-04-28', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:04:48,067 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f69f30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-04-48', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:05:07,741 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774fc70>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-05-07', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:05:27,593 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774f5b0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-05-27', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:05:47,252 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6ba30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-05-47', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:06:11,183 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f88377a3010>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-06-11', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:06:31,099 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6b400>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-06-31', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:06:50,968 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6ba30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-06-50', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:07:10,978 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6ac20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-07-10', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:07:36,154 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774db40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-07-31', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:08:04,233 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6beb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-08-04', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:08:24,072 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6ac20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-08-24', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:08:43,855 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774db40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-08-43', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:09:03,483 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6beb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-09-03', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:09:23,168 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6ac20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-09-23', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:09:47,276 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774db40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-09-47', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:10:07,357 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6beb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-10-07', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:10:26,997 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836b63910>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-10-26', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:10:46,709 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774db40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-10-46', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:11:06,142 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836f6beb0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-11-06', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:11:25,797 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836b63d00>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-11-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:11:45,733 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f883774db40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-11-45', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:12:05,324 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836b63910>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-12-05', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:12:25,832 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836b60d30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-12-25', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:12:58,117 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836b62950>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-12-58', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:13:22,176 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836b63880>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-13-22', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:13:41,832 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836b629e0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-13-41', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:14:01,267 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836b60d30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-14-01', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:14:20,970 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0d2d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-14-20', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:14:40,686 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836b63e20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-14-40', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:15:00,187 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836b63c70>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-15-00', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:15:19,639 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8837f0d2d0>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-15-19', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:15:39,167 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836b63e20>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-15-39', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:15:58,872 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836b63f40>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-15-58', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:16:18,482 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836b63910>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-16-18', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:16:42,547 INFO    MainThread:2487 [wandb_run.py:_config_callback():1324] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': 'TorchCompileWhatToCompile.FORWARD_TRAIN', 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'goal_comms_gridworld', 'env_config': {'render_mode': 'rgb_array', 'world_shape': [5, 5], 'num_agents': 2, 'max_episode_len': 10, 'goal_shift': 0}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': True, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': True, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 10000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': True, 'explore': True, 'exploration_config': {}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': '<function get_config.<locals>.policy_mapping_fn at 0x7f8836b63a30>', 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 10, 'evaluation_duration': 100, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': "MultiAgentRLModuleSpec(marl_module_class=<class 'jtc.macrl.simple_macrl.PPOTorchSimpleMACRLModule'>, module_specs={'agent_1': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None), 'agent_0': SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict={'communication_spec': {'message_dim': 8, 'comm_channels': {'agent_1': ['agent_0'], 'agent_0': ['agent_1']}, 'static': True, 'channel_fn': 'straight_through', 'n_agents': 2}, 'fcnet_hiddens': [64, 64]}, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None)", '_enable_rl_module_api': True, '_AlgorithmConfig__prior_exploration_config': {'type': 'StochasticSampling'}, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.0, 'kl_target': 0.01, 'sgd_minibatch_size': 2048, 'num_sgd_iter': 16, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'vf_share_layers': -1, '__stdout_file__': None, '__stderr_file__': None, 'lambda': 0.95, 'input': 'sampler', 'policies': {'agent_1': [None, None, None, None], 'agent_0': [None, None, None, None]}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 8, 'trial_id': '2abb8_00000', 'date': '2023-09-30_00-16-42', 'pid': 1743, 'hostname': 'DYLAN-PC', 'node_ip': '172.28.102.63'}
2023-09-30 00:16:42,639 INFO    MainThread:2487 [wandb_run.py:_finish():1934] finishing run drcope/jtc/2abb8_00000
2023-09-30 00:16:42,639 INFO    MainThread:2487 [wandb_run.py:_atexit_cleanup():2168] got exitcode: 0
2023-09-30 00:16:42,640 INFO    MainThread:2487 [wandb_run.py:_restore():2151] restore
2023-09-30 00:16:42,640 INFO    MainThread:2487 [wandb_run.py:_restore():2157] restore done
2023-09-30 00:16:49,473 INFO    MainThread:2487 [wandb_run.py:_footer_history_summary_info():3557] rendering history
2023-09-30 00:16:49,479 INFO    MainThread:2487 [wandb_run.py:_footer_history_summary_info():3589] rendering summary
2023-09-30 00:16:49,483 INFO    MainThread:2487 [wandb_run.py:_footer_sync_info():3516] logging synced files
